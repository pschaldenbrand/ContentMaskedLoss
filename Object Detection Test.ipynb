{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models.segmentation as segmentation\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "classes = ['__background__', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',\n",
    "           'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',\n",
    "           'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "resnet = segmentation.fcn_resnet101(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classify(img):\n",
    "    width = 520\n",
    "    original_shape = img.shape\n",
    "    img = cv2.resize(img, (width, width))\n",
    "\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = preprocess(img)\n",
    "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "    output = resnet(input_batch)['out'][0]\n",
    "    pixelwise_output_predictions = output.argmax(0)    \n",
    "    \n",
    "    return pixelwise_output_predictions\n",
    "\n",
    "def plot_prediction(pixelwise_output_predictions, original_shape=(200,200)):\n",
    "    # create a color pallette, selecting a color for each class\n",
    "    palette = torch.tensor([2 ** 25 - 1, 2 ** 15 - 1, 2 ** 21 - 1])\n",
    "    colors = torch.as_tensor([i for i in range(21)])[:, None] * palette\n",
    "    colors = (colors % 255).numpy().astype(\"uint8\")\n",
    "\n",
    "    # plot the semantic segmentation predictions of 21 classes in each color\n",
    "    r = Image.fromarray(pixelwise_output_predictions.byte().cpu().numpy()).resize((original_shape[1], original_shape[0]))\n",
    "    r.putpalette(colors)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.imshow(r)\n",
    "    plt.show()\n",
    "\n",
    "classify(cv2.imread('image/clint.jpg', cv2.IMREAD_COLOR)[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8257)\n",
      "tensor(0.8914)\n",
      "tensor(0.8946)\n",
      "tensor(0.8693)\n",
      "tensor(0.8681)\n",
      "tensor(0.8739)\n",
      "tensor(0.8922)\n",
      "tensor(0.8977)\n",
      "tensor(0.8855)\n",
      "tensor(0.8807)\n",
      "tensor(0.8769)\n",
      "tensor(0.9026)\n",
      "tensor(0.8971)\n",
      "tensor(0.8943)\n",
      "tensor(0.8770)\n",
      "tensor(0.8937)\n",
      "tensor(0.8838)\n",
      "tensor(0.9112)\n",
      "tensor(0.9001)\n",
      "tensor(0.8758)\n",
      "tensor(0.8874)\n",
      "tensor(0.9009)\n",
      "tensor(0.9020)\n",
      "tensor(0.9048)\n",
      "tensor(0.8836)\n",
      "tensor(0.8454)\n",
      "tensor(0.8639)\n",
      "tensor(0.8843)\n",
      "tensor(0.8560)\n",
      "tensor(0.8558)\n",
      "tensor(0.8518)\n",
      "tensor(0.8750)\n",
      "tensor(0.8643)\n",
      "tensor(0.8648)\n",
      "tensor(0.8485)\n",
      "tensor(0.8684)\n",
      "tensor(0.8645)\n",
      "tensor(0.8841)\n",
      "tensor(0.8777)\n",
      "tensor(0.8665)\n",
      "tensor(0.8732)\n",
      "tensor(0.8655)\n",
      "tensor(0.8655)\n",
      "tensor(0.8628)\n",
      "tensor(0.8498)\n",
      "tensor(0.8684)\n",
      "tensor(0.8750)\n",
      "tensor(0.8849)\n",
      "tensor(0.8939)\n",
      "tensor(0.8960)\n",
      "tensor(0.8645)\n",
      "tensor(0.9189)\n",
      "tensor(0.9010)\n",
      "tensor(0.9128)\n",
      "tensor(0.9091)\n",
      "tensor(0.8969)\n",
      "tensor(0.9063)\n",
      "tensor(0.8939)\n",
      "tensor(0.8822)\n",
      "tensor(0.8724)\n",
      "tensor(0.9116)\n",
      "tensor(0.8965)\n",
      "tensor(0.8986)\n",
      "tensor(0.9046)\n",
      "tensor(0.9248)\n",
      "tensor(0.9349)\n",
      "tensor(0.9337)\n",
      "tensor(0.9202)\n",
      "tensor(0.9236)\n",
      "tensor(0.9249)\n",
      "tensor(0.9186)\n",
      "tensor(0.9146)\n",
      "tensor(0.9034)\n",
      "tensor(0.9038)\n",
      "tensor(0.9046)\n",
      "tensor(0.8405)\n",
      "tensor(0.8665)\n",
      "tensor(0.8790)\n",
      "tensor(0.8712)\n",
      "tensor(0.8787)\n",
      "tensor(0.9269)\n",
      "tensor(0.9137)\n",
      "tensor(0.8621)\n",
      "tensor(0.8388)\n",
      "tensor(0.8884)\n",
      "tensor(0.8730)\n",
      "tensor(0.8761)\n",
      "tensor(0.8604)\n",
      "tensor(0.8704)\n",
      "tensor(0.8124)\n",
      "tensor(0.8712)\n",
      "tensor(0.8695)\n",
      "tensor(0.8925)\n",
      "tensor(0.8914)\n",
      "tensor(0.8969)\n",
      "tensor(0.9120)\n",
      "tensor(0.9146)\n",
      "tensor(0.8901)\n",
      "tensor(0.8582)\n",
      "tensor(0.8997)\n",
      "tensor(0.9189)\n",
      "tensor(0.9182)\n",
      "tensor(0.9248)\n",
      "tensor(0.9231)\n",
      "tensor(0.9232)\n",
      "tensor(0.9224)\n",
      "tensor(0.9170)\n",
      "tensor(0.9000)\n",
      "tensor(0.8887)\n",
      "tensor(0.8913)\n",
      "tensor(0.8877)\n",
      "tensor(0.8807)\n",
      "tensor(0.8903)\n",
      "tensor(0.8894)\n",
      "tensor(0.8834)\n",
      "tensor(0.9050)\n",
      "tensor(0.8728)\n",
      "tensor(0.8832)\n",
      "tensor(0.8635)\n",
      "tensor(0.8783)\n",
      "tensor(0.9044)\n",
      "tensor(0.8779)\n",
      "tensor(0.8973)\n",
      "tensor(0.8983)\n",
      "tensor(0.8980)\n",
      "tensor(0.9217)\n",
      "tensor(0.9153)\n",
      "tensor(0.9051)\n",
      "tensor(0.9039)\n",
      "tensor(0.9246)\n",
      "tensor(0.9176)\n",
      "tensor(0.9160)\n",
      "tensor(0.9161)\n",
      "tensor(0.9081)\n",
      "tensor(0.9117)\n",
      "tensor(0.9208)\n",
      "tensor(0.9158)\n",
      "tensor(0.9233)\n",
      "tensor(0.9235)\n",
      "tensor(0.9222)\n",
      "tensor(0.9196)\n",
      "tensor(0.9151)\n",
      "tensor(0.9167)\n",
      "tensor(0.9092)\n",
      "tensor(0.9153)\n",
      "tensor(0.9113)\n",
      "tensor(0.9139)\n",
      "tensor(0.9168)\n",
      "tensor(0.9167)\n",
      "tensor(0.9167)\n",
      "tensor(0.8764)\n",
      "tensor(0.9168)\n",
      "tensor(0.9075)\n",
      "tensor(0.9104)\n",
      "tensor(0.9126)\n",
      "tensor(0.9364)\n",
      "tensor(0.9347)\n",
      "tensor(0.8978)\n",
      "tensor(0.9021)\n",
      "tensor(0.8879)\n",
      "tensor(0.9050)\n",
      "tensor(0.8878)\n",
      "tensor(0.8799)\n",
      "tensor(0.8789)\n",
      "tensor(0.8766)\n",
      "tensor(0.8673)\n",
      "tensor(0.8939)\n",
      "tensor(0.8904)\n",
      "tensor(0.8893)\n",
      "tensor(0.8730)\n",
      "tensor(0.8851)\n",
      "tensor(0.8960)\n",
      "tensor(0.8797)\n",
      "tensor(0.8607)\n",
      "tensor(0.8642)\n",
      "tensor(0.8758)\n",
      "tensor(0.8880)\n",
      "tensor(0.8899)\n",
      "tensor(0.8878)\n",
      "tensor(0.8758)\n",
      "tensor(0.8819)\n",
      "tensor(0.8988)\n",
      "tensor(0.8759)\n",
      "tensor(0.8719)\n",
      "tensor(0.8618)\n",
      "tensor(0.8812)\n",
      "tensor(0.8972)\n",
      "tensor(0.8975)\n",
      "tensor(0.9100)\n",
      "tensor(0.9027)\n",
      "tensor(0.9048)\n",
      "tensor(0.9011)\n",
      "tensor(0.9055)\n",
      "tensor(0.9111)\n",
      "tensor(0.9185)\n",
      "tensor(0.9203)\n",
      "tensor(0.9146)\n",
      "tensor(0.9112)\n",
      "tensor(0.9104)\n",
      "tensor(0.9172)\n",
      "tensor(0.9158)\n",
      "tensor(0.9147)\n",
      "tensor(0.9153)\n",
      "tensor(0.9155)\n",
      "tensor(0.9147)\n",
      "tensor(0.9127)\n",
      "tensor(0.9178)\n",
      "tensor(0.9164)\n",
      "tensor(0.9187)\n",
      "tensor(0.9164)\n",
      "tensor(0.9171)\n",
      "tensor(0.9135)\n",
      "tensor(0.9107)\n",
      "tensor(0.9239)\n",
      "tensor(0.9219)\n",
      "tensor(0.9187)\n",
      "tensor(0.9223)\n",
      "tensor(0.9197)\n",
      "tensor(0.9243)\n",
      "tensor(0.9209)\n",
      "tensor(0.9259)\n",
      "tensor(0.9126)\n",
      "tensor(0.9181)\n",
      "tensor(0.9141)\n",
      "tensor(0.8863)\n",
      "tensor(0.8777)\n",
      "tensor(0.8622)\n",
      "tensor(0.9088)\n",
      "tensor(0.8905)\n",
      "tensor(0.9234)\n",
      "tensor(0.9218)\n",
      "tensor(0.9241)\n",
      "tensor(0.9371)\n",
      "tensor(0.9407)\n",
      "tensor(0.9227)\n",
      "tensor(0.9247)\n",
      "tensor(0.9204)\n",
      "tensor(0.9309)\n",
      "tensor(0.9173)\n",
      "tensor(0.9190)\n",
      "tensor(0.9280)\n",
      "tensor(0.9229)\n",
      "tensor(0.9173)\n",
      "tensor(0.9238)\n",
      "tensor(0.9072)\n",
      "tensor(0.9395)\n",
      "tensor(0.9390)\n",
      "tensor(0.9243)\n",
      "tensor(0.9346)\n",
      "tensor(0.9314)\n",
      "tensor(0.9304)\n",
      "tensor(0.9382)\n",
      "tensor(0.9119)\n",
      "tensor(0.9217)\n",
      "tensor(0.9033)\n",
      "tensor(0.9053)\n",
      "tensor(0.9169)\n",
      "tensor(0.9191)\n",
      "tensor(0.9162)\n",
      "tensor(0.9164)\n",
      "tensor(0.9076)\n",
      "tensor(0.9293)\n",
      "tensor(0.9237)\n",
      "tensor(0.9183)\n",
      "tensor(0.9107)\n",
      "tensor(0.9242)\n",
      "tensor(0.9313)\n",
      "tensor(0.9243)\n",
      "tensor(0.9371)\n",
      "tensor(0.9337)\n",
      "tensor(0.9263)\n",
      "tensor(0.9230)\n",
      "tensor(0.9201)\n",
      "tensor(0.9133)\n",
      "tensor(0.9215)\n",
      "tensor(0.9195)\n",
      "tensor(0.9233)\n",
      "tensor(0.9164)\n",
      "tensor(0.9184)\n",
      "tensor(0.9142)\n",
      "tensor(0.9138)\n",
      "tensor(0.9080)\n",
      "tensor(0.9233)\n",
      "tensor(0.9315)\n",
      "tensor(0.9313)\n",
      "tensor(0.9268)\n",
      "tensor(0.9304)\n",
      "tensor(0.9285)\n",
      "tensor(0.9352)\n",
      "tensor(0.9261)\n",
      "tensor(0.9151)\n",
      "tensor(0.9168)\n",
      "tensor(0.9244)\n",
      "tensor(0.9168)\n",
      "tensor(0.9129)\n",
      "tensor(0.9094)\n",
      "tensor(0.9115)\n",
      "tensor(0.9125)\n",
      "tensor(0.9086)\n",
      "tensor(0.9022)\n",
      "tensor(0.8068)\n",
      "tensor(0.8051)\n",
      "tensor(0.8274)\n",
      "tensor(0.8168)\n",
      "tensor(0.8114)\n",
      "tensor(0.8304)\n",
      "tensor(0.8189)\n",
      "tensor(0.8165)\n",
      "tensor(0.8049)\n",
      "tensor(0.7900)\n",
      "tensor(0.7865)\n",
      "tensor(0.7859)\n",
      "tensor(0.7745)\n",
      "tensor(0.7869)\n",
      "tensor(0.7956)\n",
      "tensor(0.8036)\n",
      "tensor(0.8090)\n",
      "tensor(0.7780)\n",
      "tensor(0.8243)\n",
      "tensor(0.7849)\n",
      "tensor(0.7843)\n",
      "tensor(0.7921)\n",
      "tensor(0.7963)\n",
      "tensor(0.7889)\n",
      "tensor(0.7846)\n",
      "tensor(0.7938)\n",
      "tensor(0.8017)\n",
      "tensor(0.7723)\n",
      "tensor(0.7965)\n",
      "tensor(0.7808)\n",
      "tensor(0.7618)\n",
      "tensor(0.7577)\n",
      "tensor(0.7635)\n",
      "tensor(0.7350)\n",
      "tensor(0.7493)\n",
      "tensor(0.7089)\n",
      "tensor(0.7410)\n",
      "tensor(0.7587)\n",
      "tensor(0.7615)\n",
      "tensor(0.7534)\n",
      "tensor(0.7494)\n",
      "tensor(0.7499)\n",
      "tensor(0.7304)\n",
      "tensor(0.7311)\n",
      "tensor(0.7290)\n",
      "tensor(0.6959)\n",
      "tensor(0.7189)\n",
      "tensor(0.7278)\n",
      "tensor(0.7070)\n",
      "tensor(0.7376)\n",
      "tensor(0.7334)\n",
      "tensor(0.7257)\n",
      "tensor(0.7459)\n",
      "tensor(0.7300)\n",
      "tensor(0.7313)\n",
      "tensor(0.7079)\n",
      "tensor(0.7027)\n",
      "tensor(0.7334)\n",
      "tensor(0.7319)\n",
      "tensor(0.7443)\n",
      "tensor(0.7548)\n",
      "tensor(0.7544)\n",
      "tensor(0.7424)\n",
      "tensor(0.7599)\n",
      "tensor(0.7731)\n",
      "tensor(0.7340)\n",
      "tensor(0.8095)\n",
      "tensor(0.7810)\n",
      "tensor(0.7737)\n",
      "tensor(0.7939)\n",
      "tensor(0.8148)\n",
      "tensor(0.8030)\n",
      "tensor(0.7829)\n",
      "tensor(0.7689)\n",
      "tensor(0.7832)\n",
      "tensor(0.8180)\n",
      "tensor(0.8216)\n",
      "tensor(0.7976)\n",
      "tensor(0.8311)\n",
      "tensor(0.7896)\n",
      "tensor(0.7844)\n",
      "tensor(0.7982)\n",
      "tensor(0.7802)\n",
      "tensor(0.7709)\n",
      "tensor(0.7741)\n",
      "tensor(0.8012)\n",
      "tensor(0.7758)\n",
      "tensor(0.7595)\n",
      "tensor(0.7873)\n",
      "tensor(0.7835)\n",
      "tensor(0.7786)\n",
      "tensor(0.7792)\n",
      "tensor(0.7695)\n",
      "tensor(0.7548)\n",
      "tensor(0.7608)\n",
      "tensor(0.7656)\n",
      "tensor(0.7654)\n",
      "tensor(0.7718)\n",
      "tensor(0.7577)\n",
      "tensor(0.7813)\n",
      "tensor(0.7655)\n",
      "tensor(0.7459)\n",
      "tensor(0.7655)\n",
      "tensor(0.7673)\n",
      "tensor(0.7561)\n",
      "tensor(0.8129)\n",
      "tensor(0.7734)\n",
      "tensor(0.7905)\n",
      "tensor(0.7687)\n",
      "tensor(0.7795)\n",
      "tensor(0.7920)\n",
      "tensor(0.7855)\n",
      "tensor(0.8089)\n",
      "tensor(0.8092)\n",
      "tensor(0.8039)\n",
      "tensor(0.7815)\n",
      "tensor(0.8201)\n",
      "tensor(0.8107)\n",
      "tensor(0.8118)\n",
      "tensor(0.8046)\n",
      "tensor(0.7839)\n",
      "tensor(0.7856)\n",
      "tensor(0.7852)\n",
      "tensor(0.7727)\n",
      "tensor(0.7979)\n",
      "tensor(0.8021)\n",
      "tensor(0.7839)\n",
      "tensor(0.7842)\n",
      "tensor(0.7888)\n",
      "tensor(0.7572)\n",
      "tensor(0.7779)\n",
      "tensor(0.7753)\n",
      "tensor(0.7740)\n",
      "tensor(0.7523)\n",
      "tensor(0.7665)\n",
      "tensor(0.7746)\n",
      "tensor(0.7666)\n",
      "tensor(0.7534)\n",
      "tensor(0.7461)\n",
      "tensor(0.7299)\n",
      "tensor(0.7623)\n",
      "tensor(0.7314)\n",
      "tensor(0.7245)\n",
      "tensor(0.7512)\n",
      "tensor(0.7604)\n",
      "tensor(0.7563)\n",
      "tensor(0.7527)\n",
      "tensor(0.7628)\n",
      "tensor(0.7800)\n",
      "tensor(0.8059)\n",
      "tensor(0.8020)\n",
      "tensor(0.7975)\n",
      "tensor(0.8170)\n",
      "tensor(0.8326)\n",
      "tensor(0.8097)\n",
      "tensor(0.7986)\n",
      "tensor(0.7962)\n",
      "tensor(0.7674)\n",
      "tensor(0.7606)\n",
      "tensor(0.7663)\n",
      "tensor(0.7780)\n",
      "tensor(0.7796)\n",
      "tensor(0.7337)\n",
      "tensor(0.7954)\n",
      "tensor(0.7565)\n",
      "tensor(0.7573)\n",
      "tensor(0.7815)\n",
      "tensor(0.8005)\n",
      "tensor(0.8170)\n",
      "tensor(0.8321)\n",
      "tensor(0.8279)\n",
      "tensor(0.8327)\n",
      "tensor(0.8204)\n",
      "tensor(0.8426)\n",
      "tensor(0.8374)\n",
      "tensor(0.7989)\n",
      "tensor(0.8083)\n",
      "tensor(0.8153)\n",
      "tensor(0.8181)\n",
      "tensor(0.8352)\n",
      "tensor(0.8116)\n",
      "tensor(0.8041)\n",
      "tensor(0.8188)\n",
      "tensor(0.8434)\n",
      "tensor(0.8453)\n",
      "tensor(0.8475)\n",
      "tensor(0.8234)\n",
      "tensor(0.8387)\n",
      "tensor(0.8403)\n",
      "tensor(0.8199)\n",
      "tensor(0.8325)\n",
      "tensor(0.8248)\n",
      "tensor(0.8282)\n",
      "tensor(0.8215)\n",
      "tensor(0.8236)\n",
      "tensor(0.8232)\n",
      "tensor(0.8208)\n",
      "tensor(0.8212)\n",
      "tensor(0.8031)\n",
      "tensor(0.8245)\n",
      "tensor(0.8028)\n",
      "tensor(0.8256)\n",
      "tensor(0.7984)\n",
      "tensor(0.7999)\n",
      "tensor(0.7889)\n",
      "tensor(0.8000)\n",
      "tensor(0.8350)\n",
      "tensor(0.8354)\n",
      "tensor(0.8375)\n",
      "tensor(0.8386)\n",
      "tensor(0.8393)\n",
      "tensor(0.8393)\n",
      "tensor(0.8345)\n",
      "tensor(0.8329)\n",
      "tensor(0.8274)\n",
      "tensor(0.8337)\n",
      "tensor(0.8324)\n",
      "tensor(0.8284)\n",
      "tensor(0.8248)\n",
      "tensor(0.8263)\n",
      "tensor(0.8313)\n",
      "tensor(0.8441)\n",
      "tensor(0.8450)\n",
      "tensor(0.8442)\n",
      "tensor(0.8322)\n",
      "tensor(0.8053)\n",
      "tensor(0.8249)\n",
      "tensor(0.8281)\n",
      "tensor(0.7890)\n",
      "tensor(0.7814)\n",
      "tensor(0.8042)\n",
      "tensor(0.7714)\n",
      "tensor(0.7646)\n",
      "tensor(0.7633)\n",
      "tensor(0.7850)\n",
      "tensor(0.7727)\n",
      "tensor(0.7728)\n",
      "tensor(0.7743)\n",
      "tensor(0.7720)\n",
      "tensor(0.8111)\n",
      "tensor(0.7807)\n",
      "tensor(0.7723)\n",
      "tensor(0.8301)\n",
      "tensor(0.8057)\n",
      "tensor(0.7959)\n",
      "tensor(0.8201)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8111)\n",
      "tensor(0.8161)\n",
      "tensor(0.8035)\n",
      "tensor(0.8280)\n",
      "tensor(0.8333)\n",
      "tensor(0.8064)\n",
      "tensor(0.8333)\n",
      "tensor(0.8062)\n",
      "tensor(0.8239)\n",
      "tensor(0.8237)\n",
      "tensor(0.8180)\n",
      "tensor(0.7946)\n",
      "tensor(0.8088)\n",
      "tensor(0.7856)\n",
      "tensor(0.7990)\n",
      "tensor(0.8272)\n",
      "tensor(0.8265)\n",
      "tensor(0.8128)\n",
      "tensor(0.8186)\n",
      "tensor(0.8204)\n",
      "tensor(0.8265)\n",
      "tensor(0.8264)\n",
      "tensor(0.8261)\n",
      "tensor(0.8167)\n",
      "tensor(0.8123)\n",
      "tensor(0.8243)\n",
      "tensor(0.8156)\n",
      "tensor(0.8011)\n",
      "tensor(0.8122)\n",
      "tensor(0.8160)\n",
      "tensor(0.8095)\n",
      "tensor(0.8093)\n",
      "tensor(0.8242)\n",
      "tensor(0.8212)\n",
      "tensor(0.8214)\n",
      "tensor(0.8174)\n",
      "tensor(0.8173)\n",
      "tensor(0.8211)\n",
      "tensor(0.8216)\n",
      "tensor(0.8147)\n",
      "tensor(0.8171)\n",
      "tensor(0.8205)\n",
      "tensor(0.7982)\n",
      "tensor(0.8092)\n",
      "tensor(0.8099)\n",
      "tensor(0.7910)\n",
      "tensor(0.7958)\n",
      "tensor(0.7990)\n",
      "tensor(0.7803)\n",
      "tensor(0.7459)\n",
      "tensor(0.7702)\n",
      "tensor(0.7627)\n",
      "tensor(0.7691)\n",
      "tensor(0.7703)\n",
      "tensor(0.8697)\n",
      "tensor(0.8777)\n",
      "tensor(0.8754)\n",
      "tensor(0.9169)\n",
      "tensor(0.9225)\n",
      "tensor(0.8855)\n",
      "tensor(0.9244)\n",
      "tensor(0.9386)\n",
      "tensor(0.9312)\n",
      "tensor(0.9292)\n",
      "tensor(0.9211)\n",
      "tensor(0.9201)\n",
      "tensor(0.9166)\n",
      "tensor(0.9294)\n",
      "tensor(0.9410)\n",
      "tensor(0.9252)\n",
      "tensor(0.9325)\n",
      "tensor(0.9261)\n",
      "tensor(0.9214)\n",
      "tensor(0.9193)\n",
      "tensor(0.9244)\n",
      "tensor(0.9158)\n",
      "tensor(0.9325)\n",
      "tensor(0.9259)\n",
      "tensor(0.9281)\n",
      "tensor(0.9249)\n",
      "tensor(0.9192)\n",
      "tensor(0.9232)\n",
      "tensor(0.9111)\n",
      "tensor(0.9286)\n",
      "tensor(0.9302)\n",
      "tensor(0.9241)\n",
      "tensor(0.9195)\n",
      "tensor(0.8946)\n",
      "tensor(0.9228)\n",
      "tensor(0.8951)\n",
      "tensor(0.8922)\n",
      "tensor(0.9149)\n",
      "tensor(0.8929)\n",
      "tensor(0.8662)\n",
      "tensor(0.8848)\n",
      "tensor(0.8823)\n",
      "tensor(0.8749)\n",
      "tensor(0.8710)\n",
      "tensor(0.8785)\n",
      "tensor(0.8925)\n",
      "tensor(0.8885)\n",
      "tensor(0.8924)\n",
      "tensor(0.8952)\n",
      "tensor(0.8963)\n",
      "tensor(0.8979)\n",
      "tensor(0.9069)\n",
      "tensor(0.8900)\n",
      "tensor(0.8911)\n",
      "tensor(0.8988)\n",
      "tensor(0.8956)\n",
      "tensor(0.9132)\n",
      "tensor(0.9218)\n",
      "tensor(0.9186)\n",
      "tensor(0.9216)\n",
      "tensor(0.9125)\n",
      "tensor(0.9202)\n",
      "tensor(0.9182)\n",
      "tensor(0.9180)\n",
      "tensor(0.9097)\n",
      "tensor(0.9134)\n",
      "tensor(0.9015)\n",
      "tensor(0.9092)\n",
      "tensor(0.9088)\n",
      "tensor(0.8860)\n",
      "tensor(0.8870)\n",
      "tensor(0.8922)\n",
      "tensor(0.8975)\n",
      "tensor(0.8936)\n",
      "tensor(0.8994)\n",
      "tensor(0.8540)\n",
      "tensor(0.8983)\n",
      "tensor(0.9002)\n",
      "tensor(0.8950)\n",
      "tensor(0.9107)\n",
      "tensor(0.8993)\n",
      "tensor(0.9263)\n",
      "tensor(0.9279)\n",
      "tensor(0.8916)\n",
      "tensor(0.8725)\n",
      "tensor(0.9185)\n",
      "tensor(0.9068)\n",
      "tensor(0.8940)\n",
      "tensor(0.8933)\n",
      "tensor(0.9335)\n",
      "tensor(0.9270)\n",
      "tensor(0.9213)\n",
      "tensor(0.9257)\n",
      "tensor(0.9231)\n",
      "tensor(0.9057)\n",
      "tensor(0.9310)\n",
      "tensor(0.9318)\n",
      "tensor(0.9101)\n",
      "tensor(0.9127)\n",
      "tensor(0.9012)\n",
      "tensor(0.9129)\n",
      "tensor(0.9199)\n",
      "tensor(0.9128)\n",
      "tensor(0.8995)\n",
      "tensor(0.8731)\n",
      "tensor(0.8818)\n",
      "tensor(0.8573)\n",
      "tensor(0.8581)\n",
      "tensor(0.8463)\n",
      "tensor(0.8785)\n",
      "tensor(0.8979)\n",
      "tensor(0.8599)\n",
      "tensor(0.8797)\n",
      "tensor(0.8958)\n",
      "tensor(0.8913)\n",
      "tensor(0.8698)\n",
      "tensor(0.8397)\n",
      "tensor(0.8235)\n",
      "tensor(0.8394)\n",
      "tensor(0.8309)\n",
      "tensor(0.8576)\n",
      "tensor(0.8475)\n",
      "tensor(0.8483)\n",
      "tensor(0.8906)\n",
      "tensor(0.8680)\n",
      "tensor(0.8898)\n",
      "tensor(0.8844)\n",
      "tensor(0.8752)\n",
      "tensor(0.8683)\n",
      "tensor(0.8762)\n",
      "tensor(0.8781)\n",
      "tensor(0.8757)\n",
      "tensor(0.8760)\n",
      "tensor(0.8795)\n",
      "tensor(0.8626)\n",
      "tensor(0.8725)\n",
      "tensor(0.8646)\n",
      "tensor(0.8659)\n",
      "tensor(0.8661)\n",
      "tensor(0.8591)\n",
      "tensor(0.8620)\n",
      "tensor(0.8527)\n",
      "tensor(0.8580)\n",
      "tensor(0.8552)\n",
      "tensor(0.8606)\n",
      "tensor(0.8645)\n",
      "tensor(0.8602)\n",
      "tensor(0.8576)\n",
      "tensor(0.8613)\n",
      "tensor(0.8657)\n",
      "tensor(0.8843)\n",
      "tensor(0.8835)\n",
      "tensor(0.8972)\n",
      "tensor(0.8728)\n",
      "tensor(0.9193)\n",
      "tensor(0.9332)\n",
      "tensor(0.9051)\n",
      "tensor(0.9077)\n",
      "tensor(0.9105)\n",
      "tensor(0.8979)\n",
      "tensor(0.8883)\n",
      "tensor(0.8918)\n",
      "tensor(0.8764)\n",
      "tensor(0.8670)\n",
      "tensor(0.8756)\n",
      "tensor(0.9259)\n",
      "tensor(0.9270)\n",
      "tensor(0.9200)\n",
      "tensor(0.9169)\n",
      "tensor(0.8855)\n",
      "tensor(0.9021)\n",
      "tensor(0.9069)\n",
      "tensor(0.8686)\n",
      "tensor(0.9017)\n",
      "tensor(0.8281)\n",
      "tensor(0.8231)\n",
      "tensor(0.8863)\n",
      "tensor(0.8536)\n",
      "tensor(0.8584)\n",
      "tensor(0.8426)\n",
      "tensor(0.8222)\n",
      "tensor(0.8347)\n",
      "tensor(0.8246)\n",
      "tensor(0.8990)\n",
      "tensor(0.9095)\n",
      "tensor(0.9010)\n",
      "tensor(0.8910)\n",
      "tensor(0.8691)\n",
      "tensor(0.9073)\n",
      "tensor(0.8710)\n",
      "tensor(0.8698)\n",
      "tensor(0.8863)\n",
      "tensor(0.8715)\n",
      "tensor(0.8949)\n",
      "tensor(0.9075)\n",
      "tensor(0.9150)\n",
      "tensor(0.9112)\n",
      "tensor(0.9235)\n",
      "tensor(0.9220)\n",
      "tensor(0.9172)\n",
      "tensor(0.8848)\n",
      "tensor(0.8939)\n",
      "tensor(0.9202)\n",
      "tensor(0.9141)\n",
      "tensor(0.9077)\n",
      "tensor(0.9369)\n",
      "tensor(0.9382)\n",
      "tensor(0.9164)\n",
      "tensor(0.9350)\n",
      "tensor(0.9320)\n",
      "tensor(0.9377)\n",
      "tensor(0.9401)\n",
      "tensor(0.9299)\n",
      "tensor(0.9359)\n",
      "tensor(0.9267)\n",
      "tensor(0.9273)\n",
      "tensor(0.9197)\n",
      "tensor(0.9112)\n",
      "tensor(0.9123)\n",
      "tensor(0.9135)\n",
      "tensor(0.9118)\n",
      "tensor(0.9218)\n",
      "tensor(0.9202)\n",
      "tensor(0.9190)\n",
      "tensor(0.9231)\n",
      "tensor(0.8799)\n",
      "tensor(0.9234)\n",
      "tensor(0.8678)\n",
      "tensor(0.8843)\n",
      "tensor(0.9054)\n",
      "tensor(0.9326)\n",
      "tensor(0.9269)\n",
      "tensor(0.9166)\n",
      "tensor(0.9128)\n",
      "tensor(0.8712)\n",
      "tensor(0.9079)\n",
      "tensor(0.8967)\n",
      "tensor(0.8883)\n",
      "tensor(0.8958)\n",
      "tensor(0.8989)\n",
      "tensor(0.9089)\n",
      "tensor(0.9222)\n",
      "tensor(0.9254)\n",
      "tensor(0.9067)\n",
      "tensor(0.9099)\n",
      "tensor(0.9005)\n",
      "tensor(0.8952)\n",
      "tensor(0.8914)\n",
      "tensor(0.8913)\n",
      "tensor(0.8765)\n",
      "tensor(0.8730)\n",
      "tensor(0.8719)\n",
      "tensor(0.8822)\n",
      "tensor(0.8906)\n",
      "tensor(0.9114)\n",
      "tensor(0.8945)\n",
      "tensor(0.8821)\n",
      "tensor(0.8874)\n",
      "tensor(0.8896)\n",
      "tensor(0.8890)\n",
      "tensor(0.8864)\n",
      "tensor(0.8871)\n",
      "tensor(0.8962)\n",
      "tensor(0.8830)\n",
      "tensor(0.8913)\n",
      "tensor(0.8920)\n",
      "tensor(0.9162)\n",
      "tensor(0.8753)\n",
      "tensor(0.8874)\n",
      "tensor(0.8873)\n",
      "tensor(0.8827)\n",
      "tensor(0.8793)\n",
      "tensor(0.8729)\n",
      "tensor(0.9041)\n",
      "tensor(0.8738)\n",
      "tensor(0.8992)\n",
      "tensor(0.8951)\n",
      "tensor(0.8818)\n",
      "tensor(0.8799)\n",
      "tensor(0.8782)\n",
      "tensor(0.8908)\n",
      "tensor(0.8674)\n",
      "tensor(0.8772)\n",
      "tensor(0.8826)\n",
      "tensor(0.9072)\n",
      "tensor(0.8874)\n",
      "tensor(0.8960)\n",
      "tensor(0.8932)\n",
      "tensor(0.8767)\n",
      "tensor(0.8820)\n",
      "tensor(0.9000)\n",
      "tensor(0.9174)\n",
      "tensor(0.8973)\n",
      "tensor(0.8936)\n",
      "tensor(0.9114)\n",
      "tensor(0.9106)\n",
      "tensor(0.9192)\n",
      "tensor(0.8977)\n",
      "tensor(0.9264)\n",
      "tensor(0.9174)\n",
      "tensor(0.7825)\n",
      "tensor(0.7866)\n",
      "tensor(0.8321)\n",
      "tensor(0.7987)\n",
      "tensor(0.8431)\n",
      "tensor(0.8360)\n",
      "tensor(0.8300)\n",
      "tensor(0.8153)\n",
      "tensor(0.8250)\n",
      "tensor(0.8335)\n",
      "tensor(0.7659)\n",
      "tensor(0.8137)\n",
      "tensor(0.7980)\n",
      "tensor(0.7887)\n",
      "tensor(0.7921)\n",
      "tensor(0.7969)\n",
      "tensor(0.7977)\n",
      "tensor(0.7894)\n",
      "tensor(0.7842)\n",
      "tensor(0.8085)\n",
      "tensor(0.7841)\n",
      "tensor(0.7924)\n",
      "tensor(0.7831)\n",
      "tensor(0.7646)\n",
      "tensor(0.7732)\n",
      "tensor(0.7960)\n",
      "tensor(0.8096)\n",
      "tensor(0.8166)\n",
      "tensor(0.8341)\n",
      "tensor(0.8110)\n",
      "tensor(0.8005)\n",
      "tensor(0.8325)\n",
      "tensor(0.7882)\n",
      "tensor(0.7582)\n",
      "tensor(0.7645)\n",
      "tensor(0.7829)\n",
      "tensor(0.7583)\n",
      "tensor(0.7612)\n",
      "tensor(0.7637)\n",
      "tensor(0.7602)\n",
      "tensor(0.8176)\n",
      "tensor(0.8182)\n",
      "tensor(0.7872)\n",
      "tensor(0.8010)\n",
      "tensor(0.8108)\n",
      "tensor(0.8093)\n",
      "tensor(0.7788)\n",
      "tensor(0.7913)\n",
      "tensor(0.7976)\n",
      "tensor(0.7986)\n",
      "tensor(0.7931)\n",
      "tensor(0.7857)\n",
      "tensor(0.7887)\n",
      "tensor(0.7918)\n",
      "tensor(0.7860)\n",
      "tensor(0.7982)\n",
      "tensor(0.7795)\n",
      "tensor(0.7863)\n",
      "tensor(0.7626)\n",
      "tensor(0.7762)\n",
      "tensor(0.7837)\n",
      "tensor(0.7819)\n",
      "tensor(0.7773)\n",
      "tensor(0.7788)\n",
      "tensor(0.7719)\n",
      "tensor(0.7805)\n",
      "tensor(0.7811)\n",
      "tensor(0.7879)\n",
      "tensor(0.7904)\n",
      "tensor(0.7864)\n",
      "tensor(0.7870)\n",
      "tensor(0.7836)\n",
      "tensor(0.7888)\n",
      "tensor(0.7752)\n",
      "tensor(0.7892)\n",
      "tensor(0.7570)\n",
      "tensor(0.8237)\n",
      "tensor(0.8049)\n",
      "tensor(0.8152)\n",
      "tensor(0.8438)\n",
      "tensor(0.7964)\n",
      "tensor(0.8222)\n",
      "tensor(0.8072)\n",
      "tensor(0.8350)\n",
      "tensor(0.8036)\n",
      "tensor(0.7953)\n",
      "tensor(0.8206)\n",
      "tensor(0.7948)\n",
      "tensor(0.7792)\n",
      "tensor(0.8155)\n",
      "tensor(0.8124)\n",
      "tensor(0.8293)\n",
      "tensor(0.8343)\n",
      "tensor(0.8135)\n",
      "tensor(0.8277)\n",
      "tensor(0.8174)\n",
      "tensor(0.8150)\n",
      "tensor(0.7772)\n",
      "tensor(0.7843)\n",
      "tensor(0.7748)\n",
      "tensor(0.7462)\n",
      "tensor(0.7345)\n",
      "tensor(0.6926)\n",
      "tensor(0.7399)\n",
      "tensor(0.7262)\n",
      "tensor(0.7179)\n",
      "tensor(0.7410)\n",
      "tensor(0.7594)\n",
      "tensor(0.7552)\n",
      "tensor(0.7736)\n",
      "tensor(0.8073)\n",
      "tensor(0.8058)\n",
      "tensor(0.8075)\n",
      "tensor(0.7918)\n",
      "tensor(0.7861)\n",
      "tensor(0.7820)\n",
      "tensor(0.7636)\n",
      "tensor(0.7821)\n",
      "tensor(0.7945)\n",
      "tensor(0.8233)\n",
      "tensor(0.8135)\n",
      "tensor(0.8357)\n",
      "tensor(0.8342)\n",
      "tensor(0.8328)\n",
      "tensor(0.8359)\n",
      "tensor(0.8339)\n",
      "tensor(0.8363)\n",
      "tensor(0.8392)\n",
      "tensor(0.8381)\n",
      "tensor(0.8349)\n",
      "tensor(0.8343)\n",
      "tensor(0.8392)\n",
      "tensor(0.8389)\n",
      "tensor(0.8354)\n",
      "tensor(0.8351)\n",
      "tensor(0.8394)\n",
      "tensor(0.8358)\n",
      "tensor(0.8406)\n",
      "tensor(0.8361)\n",
      "tensor(0.8437)\n",
      "tensor(0.8311)\n",
      "tensor(0.8262)\n",
      "tensor(0.8322)\n",
      "tensor(0.8428)\n",
      "tensor(0.8335)\n",
      "tensor(0.8363)\n",
      "tensor(0.8241)\n",
      "tensor(0.8266)\n",
      "tensor(0.8411)\n",
      "tensor(0.8345)\n",
      "tensor(0.8103)\n",
      "tensor(0.8425)\n",
      "tensor(0.8755)\n",
      "tensor(0.8477)\n",
      "tensor(0.8720)\n",
      "tensor(0.8871)\n",
      "tensor(0.8852)\n",
      "tensor(0.8857)\n",
      "tensor(0.8640)\n",
      "tensor(0.8550)\n",
      "tensor(0.8387)\n",
      "tensor(0.8251)\n",
      "tensor(0.8616)\n",
      "tensor(0.8696)\n",
      "tensor(0.8769)\n",
      "tensor(0.8650)\n",
      "tensor(0.8670)\n",
      "tensor(0.8737)\n",
      "tensor(0.8515)\n",
      "tensor(0.8655)\n",
      "tensor(0.8507)\n",
      "tensor(0.8468)\n",
      "tensor(0.8565)\n",
      "tensor(0.8430)\n",
      "tensor(0.8699)\n",
      "tensor(0.8458)\n",
      "tensor(0.8396)\n",
      "tensor(0.8591)\n",
      "tensor(0.8307)\n",
      "tensor(0.8150)\n",
      "tensor(0.8053)\n",
      "tensor(0.8058)\n",
      "tensor(0.8094)\n",
      "tensor(0.8244)\n",
      "tensor(0.8285)\n",
      "tensor(0.8635)\n",
      "tensor(0.8614)\n",
      "tensor(0.8747)\n",
      "tensor(0.8599)\n",
      "tensor(0.8696)\n",
      "tensor(0.8638)\n",
      "tensor(0.8449)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8709)\n",
      "tensor(0.8491)\n",
      "tensor(0.8618)\n",
      "tensor(0.8609)\n",
      "tensor(0.8462)\n",
      "tensor(0.8461)\n",
      "tensor(0.8467)\n",
      "tensor(0.8422)\n",
      "tensor(0.8535)\n",
      "tensor(0.8498)\n",
      "tensor(0.8498)\n",
      "tensor(0.8538)\n",
      "tensor(0.8506)\n",
      "tensor(0.8508)\n",
      "tensor(0.8439)\n",
      "tensor(0.8311)\n",
      "tensor(0.8130)\n",
      "tensor(0.8203)\n",
      "tensor(0.8221)\n",
      "tensor(0.8261)\n",
      "tensor(0.8185)\n",
      "tensor(0.8205)\n",
      "tensor(0.8167)\n",
      "tensor(0.8114)\n",
      "tensor(0.8136)\n",
      "tensor(0.8195)\n",
      "tensor(0.8139)\n",
      "tensor(0.8134)\n",
      "tensor(0.8285)\n",
      "tensor(0.8246)\n",
      "tensor(0.8351)\n",
      "tensor(0.8335)\n",
      "tensor(0.8232)\n",
      "tensor(0.7980)\n",
      "tensor(0.8790)\n",
      "tensor(0.8613)\n",
      "tensor(0.8662)\n",
      "tensor(0.8927)\n",
      "tensor(0.8735)\n",
      "tensor(0.8844)\n",
      "tensor(0.8910)\n",
      "tensor(0.8893)\n",
      "tensor(0.8636)\n",
      "tensor(0.8759)\n",
      "tensor(0.8704)\n",
      "tensor(0.8690)\n",
      "tensor(0.8847)\n",
      "tensor(0.8707)\n",
      "tensor(0.8621)\n",
      "tensor(0.8588)\n",
      "tensor(0.8461)\n",
      "tensor(0.8605)\n",
      "tensor(0.8773)\n",
      "tensor(0.8720)\n",
      "tensor(0.8499)\n",
      "tensor(0.8659)\n",
      "tensor(0.8589)\n",
      "tensor(0.8437)\n",
      "tensor(0.8533)\n",
      "tensor(0.8500)\n",
      "tensor(0.8781)\n",
      "tensor(0.8805)\n",
      "tensor(0.8835)\n",
      "tensor(0.8814)\n",
      "tensor(0.8792)\n",
      "tensor(0.8570)\n",
      "tensor(0.8679)\n",
      "tensor(0.8521)\n",
      "tensor(0.8691)\n",
      "tensor(0.8576)\n",
      "tensor(0.8619)\n",
      "tensor(0.8579)\n",
      "tensor(0.8620)\n",
      "tensor(0.8539)\n",
      "tensor(0.8499)\n",
      "tensor(0.8384)\n",
      "tensor(0.8433)\n",
      "tensor(0.8303)\n",
      "tensor(0.8395)\n",
      "tensor(0.8671)\n",
      "tensor(0.8613)\n",
      "tensor(0.8559)\n",
      "tensor(0.8417)\n",
      "tensor(0.8540)\n",
      "tensor(0.8493)\n",
      "tensor(0.8464)\n",
      "tensor(0.8567)\n",
      "tensor(0.8698)\n",
      "tensor(0.8594)\n",
      "tensor(0.8673)\n",
      "tensor(0.8693)\n",
      "tensor(0.8711)\n",
      "tensor(0.8627)\n",
      "tensor(0.8681)\n",
      "tensor(0.8793)\n",
      "tensor(0.8787)\n",
      "tensor(0.8708)\n",
      "tensor(0.8792)\n",
      "tensor(0.8768)\n",
      "tensor(0.8749)\n",
      "tensor(0.8775)\n",
      "tensor(0.8608)\n",
      "tensor(0.8693)\n",
      "tensor(0.8631)\n",
      "tensor(0.8468)\n",
      "tensor(0.8508)\n",
      "tensor(0.8422)\n",
      "tensor(0.8584)\n",
      "tensor(0.8425)\n",
      "tensor(0.8949)\n",
      "tensor(0.9019)\n",
      "tensor(0.9031)\n",
      "tensor(0.9162)\n",
      "tensor(0.8974)\n",
      "tensor(0.8947)\n",
      "tensor(0.8982)\n",
      "tensor(0.8569)\n",
      "tensor(0.8696)\n",
      "tensor(0.8654)\n",
      "tensor(0.9029)\n",
      "tensor(0.8545)\n",
      "tensor(0.8876)\n",
      "tensor(0.9180)\n",
      "tensor(0.8940)\n",
      "tensor(0.8650)\n",
      "tensor(0.8813)\n",
      "tensor(0.8883)\n",
      "tensor(0.9081)\n",
      "tensor(0.8973)\n",
      "tensor(0.9085)\n",
      "tensor(0.8833)\n",
      "tensor(0.8943)\n",
      "tensor(0.8979)\n",
      "tensor(0.9081)\n",
      "tensor(0.8790)\n",
      "tensor(0.8795)\n",
      "tensor(0.8752)\n",
      "tensor(0.8955)\n",
      "tensor(0.9156)\n",
      "tensor(0.8993)\n",
      "tensor(0.8949)\n",
      "tensor(0.9197)\n",
      "tensor(0.9140)\n",
      "tensor(0.9086)\n",
      "tensor(0.9191)\n",
      "tensor(0.9196)\n",
      "tensor(0.9058)\n",
      "tensor(0.9048)\n",
      "tensor(0.9058)\n",
      "tensor(0.8976)\n",
      "tensor(0.9168)\n",
      "tensor(0.9042)\n",
      "tensor(0.9223)\n",
      "tensor(0.9095)\n",
      "tensor(0.9114)\n",
      "tensor(0.9060)\n",
      "tensor(0.9293)\n",
      "tensor(0.9144)\n",
      "tensor(0.9313)\n",
      "tensor(0.9062)\n",
      "tensor(0.9100)\n",
      "tensor(0.9089)\n",
      "tensor(0.9131)\n",
      "tensor(0.9036)\n",
      "tensor(0.8981)\n",
      "tensor(0.8965)\n",
      "tensor(0.9004)\n",
      "tensor(0.9029)\n",
      "tensor(0.8944)\n",
      "tensor(0.9002)\n",
      "tensor(0.8987)\n",
      "tensor(0.8996)\n",
      "tensor(0.9012)\n",
      "tensor(0.8994)\n",
      "tensor(0.9000)\n",
      "tensor(0.9033)\n",
      "tensor(0.8992)\n",
      "tensor(0.8981)\n",
      "tensor(0.9212)\n",
      "tensor(0.9109)\n",
      "tensor(0.9115)\n",
      "tensor(0.9059)\n",
      "tensor(0.9009)\n",
      "tensor(0.8315)\n",
      "tensor(0.8964)\n",
      "tensor(0.9087)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e1a4b10eedc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_canvases\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mcanvas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_canvases\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[1;31m#print('pred')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;31m#plot_prediction(pred)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-7b705f2a5acf>\u001b[0m in \u001b[0;36mclassify\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0minput_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# create a mini-batch as expected by the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'out'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mpixelwise_output_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\torchvision\\models\\segmentation\\_utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# contract: features is a dict of tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\torchvision\\models\\_utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                 \u001b[0mout_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_layers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\torchvision\\models\\resnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0midentity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 342\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from paint import *\n",
    "\n",
    "img_dir = 'VOC2012/JPEGImages/'\n",
    "\n",
    "actor_fns = ['pretrained_models/gan/actor.pkl', \n",
    "             'pretrained_models/cml1/actor.pkl']\n",
    "renderer_fn = 'renderer_constrained.pkl'\n",
    "\n",
    "info_dict = {}\n",
    "\n",
    "for img_fn in os.listdir(img_dir):\n",
    "    img_results = {}\n",
    "    for actor_fn in actor_fns:\n",
    "        #print(img_fn)\n",
    "        \n",
    "        img_results[actor_fn] = []\n",
    "        \n",
    "        true_pred = classify(cv2.imread(img_dir + img_fn, cv2.IMREAD_COLOR)[:,:,::-1])\n",
    "        actions_whole, actions_divided, all_canvases, final_result \\\n",
    "                = paint(actor_fn, renderer_fn, max_step=150, div=1, discrete_colors=False, img=img_dir + img_fn)\n",
    "        #print('true')\n",
    "        #plot_prediction(true_pred)\n",
    "        #for canvas in all_canvases:\n",
    "        for i in range(0, len(all_canvases), 10):\n",
    "            canvas = all_canvases[i]\n",
    "            pred = classify(canvas)\n",
    "            #print('pred')\n",
    "            #plot_prediction(pred)\n",
    "            match = torch.eq(pred, true_pred)\n",
    "            #plt.matshow(match)\n",
    "            #plt.show()\n",
    "            prop_correct = 1.0 * torch.sum(match) / (match.flatten().shape[0])\n",
    "            \n",
    "            img_results[actor_fn].append(prop_correct)\n",
    "            \n",
    "            print(prop_correct)\n",
    "    info_dict[img_fn] = img_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([75])\n",
      "torch.Size([75])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJztnXuYFOWVuN8zwyADKhPFuMiAYEKUywADA15AQRElGhEviET9gTHiDU3UaDC6OiHZDZFsMGzcZL3ieg0aRQjesoiuIEkYgtyDgqIMxIggBJgZmcv5/dE9TU9PdVf1vab7vM8zz3R/9XXVqe6qU+c753znE1XFMAzDyA8Ksi2AYRiGkTlM6RuGYeQRpvQNwzDyCFP6hmEYeYQpfcMwjDzClL5hGEYeYUrfMAwjj/Ck9EVkrIhsEpHNIjLdYXsPEVkiIqtEZI2InBdsby8ij4vIWhFZLSKjUiy/YRiGEQeuSl9ECoEHgW8CfYFJItI3ots9wDxVLQcuB/4r2H4tgKqWAWOA/xARG10YhmFkiXYe+gwDNqvqhwAi8hxwIbAhrI8CRwZfdwZ2BF/3BRYDqOpnIrIHqAD+Eu1gXbp00Z49e8ZxCoZhGMbKlSs/V9Vj3Pp5UfrdgG1h76uBkyP6VAJviMjNQCfg7GD7auDC4IOiOzAk+D+q0u/ZsydVVVUexDIMwzCaEZGPvfTz4moRh7bIgj2TgLmqWgqcBzwZdOM8RuAhUQU8ALwLNDgIO1VEqkSkaufOnV7kNgzDMBLAi9KvJmCdN1PKIfdNM9cA8wBUdTnQAeiiqg2qequqDlLVC4ES4IPIA6jqQ6paoaoVxxzjOjoxDMMwEsSL0l8B9BaRXiLSnkCgdkFEn0+A0QAi0oeA0t8pIh1FpFOwfQzQoKobMAzDMLKCq09fVRtEZBrwOlAIPKaq60VkBlClqguA24GHReRWAq6fKaqqIvJV4HURaQK2A1el7UyMNk19fT3V1dXU1dVlWxTD8DUdOnSgtLSUoqKihD4vfqunX1FRoRbIzT8++ugjjjjiCI4++mhEnMJIhmGoKrt27WLfvn306tWrxTYRWamqFW77sJx5wxfU1dWZwjcMF0SEo48+OqkRsSl9wzeYwjcMd5K9T0zpG4Zh5BGm9A3DMPIIU/qGkQLmz5/Phg3xZyMvWLCAmTNnpkSGyspKfvGLX6RkX6k4lpc+9fX1DBkyJJWihRg7dizbt2+P6zNbt27lmWeeSYs8AKNGjXKsONCzZ08+//zztB03HFP6Rptk/qrtDJ/5Jr2mL2L4zDeZvyq+mzsRGhsbo8sTQ+k3NLSahB5i3LhxTJ/eqnBt3rB06VJOO+20lO+3traW3bt3061bt7g+l4jSj/X7+hFT+kabY/6q7dz14lq276lFge17arnrxbVJKf6tW7dy0kknMXnyZAYMGMCll15KTU0NPXv2ZMaMGYwYMYLnn3+eLVu2MHbsWIYMGcLpp5/O3/72N959910WLFjAHXfcwaBBg9iyZQujRo3iRz/6ESNHjuRXv/oVCxcu5OSTT6a8vJyzzz6bf/zjHwDMnTuXadOmATBlyhRuueUWTjvtNE444QReeOGFkHyzZs1i6NChDBgwgPvuuy/U/m//9m+ceOKJnH322WzatCnmOY4aNYpbb72VM844gz59+rBixQouvvhievfuzT333BPq98tf/pL+/fvTv39/HnjgAddjOX0nkcyZM4e+ffsyYMAALr/88lD7a6+9xje/+U0AfvKTn3DSSScxZswYJk2aFBolPPzwwwwdOpSBAwdyySWXUFNT4/p9vfXWW4waNQqAGTNmMHToUPr378/UqVNpTlPfvHkzZ599NgMHDmTw4MFs2bKF6dOn88477zBo0CBmz55NXV0dV199NWVlZZSXl7NkyZLQ7zZhwgQuuOACzjnnnFbne/jhh3P77bczePBgRo8eTWR5maamJiZPntzie88YquqrvyFDhqiRf2zYsMFz39N+tliP/+EfWv2d9rPFCR//o48+UkCXLl2qqqpXX321zpo1S48//nj9+c9/Hup31lln6fvvv6+qqn/605/0zDPPVFXVyZMn6/PPPx/qN3LkSL3hhhtC73fv3q1NTU2qqvrwww/rbbfdpqqqjz/+uN50002hfVx66aXa2Nio69ev16997Wuqqvr666/rtddeq01NTdrY2Kjnn3++vv3221pVVaX9+/fXAwcO6N69e/VrX/uazpo1K+o5jhw5Uu+8805VVX3ggQe0a9euumPHDq2rq9Nu3brp559/Htrn/v37dd++fdq3b1/961//GvNY0b6T++67L9Sna9euWldXp6qqX3zxRUimoUOH6oEDB3TFihU6cOBAramp0X/+85/69a9/PfTZzz//PNT/7rvv1jlz5sT8vlRVb775Zl28OHA97Nq1K9R+5ZVX6oIFC1RVddiwYfriiy+qqmptba0eOHBAlyxZoueff36o/y9+8QudMmWKqqpu3LhRu3fvrrW1tfr4449rt27dWuw7HECfeuopVVX98Y9/HPqNR44cqcuXL9fLL79cf/rTn4b6H3/88bpz586ov10kTvcLgcmyrjrWS5VNw/AVO/bUxtXule7duzN8+HAArrzySubMmQPAxIkTAdi/fz/vvvsuEyZMCH3myy+/jLq/5s8BVFdXM3HiRP7+979z8ODBVhNrmhk/fjwFBQX07ds3NBp44403eOONNygvLw/J8cEHH7Bv3z4uuugiOnbsCARcRW409ykrK6Nfv3507doVgBNOOIFt27axdOlSLrroIjp16gTAxRdfzDvvvENTU5Pjsbx+JwMGDOCKK65g/PjxjB8/HoAdO3Zw1FFH0bFjR5YuXcqFF15IcXExABdccEHos+vWreOee+5hz5497N+/n3PPPTfm9wWwbNmy0EhhyZIl3H///dTU1LB792769evHqFGj2L59OxdddBEQmOXqxNKlS7n55psBOOmkkzj++ON5//33ARgzZgxHHXWU4+cKCgpCv/+VV17JxRdfHNp23XXXcdlll3H33Xc7fjbdmHvHaHMcV1IcV7tXIvOfm983K8CmpiZKSkp47733Qn8bN26Mur/mzwHcfPPNTJs2jbVr1/Lf//3fUSfXHHbYYaHXGnRDqCp33XVX6JibN2/mmmuucZTZjeb9FxQUtDhWQUEBDQ0NoWM64XQsr9/JokWLuOmmm1i5ciVDhgyhoaGBV199NaTAYx13ypQp/PrXv2bt2rXcd999Lb47p+/rww8/pHv37rRv3566ujpuvPFGXnjhBdauXcu1115LXV1dzOOFE6tf+O/rRvh3d9ppp7FkyZKslRwxpW+0Oe4490SKiwpbtBUXFXLHuScmtd9PPvmE5cuXA/Dss88yYsSIFtuPPPJIevXqxfPPPw8EFMLq1asBOOKII9i3b1/Ufe/duzcUVHziiSfikuvcc8/lscceY//+/QBs376dzz77jDPOOIOXXnqJ2tpa9u3bx8KFC+ParxNnnHEG8+fPp6amhgMHDvDSSy9x+umnRz1WrO+kmaamJrZt28aZZ57J/fffH7LYw/35I0aMYOHChdTV1bF//34WLVoU+vy+ffvo2rUr9fX1PP30067n8OqrrzJ27FiAkGLt0qUL+/fvD/n9jzzySEpLS5k/fz4QGJ3U1NS0+h3POOOM0DHff/99PvnkE0480f06a2pqCh3rmWeeaXEtXXPNNZx33nlMmDAhK0FgU/pGm2N8eTd+dnEZ3UqKEaBbSTE/u7iM8eXxZWpE0qdPH5544gkGDBjA7t27ueGGG1r1efrpp3n00UcZOHAg/fr14+WXXwbg8ssvZ9asWZSXl7Nly5ZWn6usrGTChAmcfvrpdOnSJS65zjnnHL797W9z6qmnUlZWxqWXXsq+ffsYPHgwEydOZNCgQVxyySWcfvrpiZ14GIMHD2bKlCkMGzaMk08+me9+97uUl5fHPFa076SZxsZGrrzyylAw9NZbb+WII47ggw8+4KSTTgJg6NChjBs3joEDB3LxxRdTUVFB586dgUCA9+STT2bMmDGh/rF47bXXQkq/pKSEa6+9lrKyMsaPH8/QoUND/Z588knmzJnDgAEDOO200/j0008ZMGAA7dq1Y+DAgcyePZsbb7yRxsZGysrKmDhxInPnzm0xughn0KBBodedOnVi/fr1DBkyhDfffJN77723Rd/bbruNwYMHc9VVV9HU1OR6TinFi+M/k38WyM1P4gnkpoOPPvpI+/Xrl1UZ8ol33nlHr7vuuhZt+/btU1XVAwcO6JAhQ3TlypVx77eurk79oEM6deqU1v1bINcwjDbFiBEjWrnPpk6dyoYNG6irq2Py5MkMHjw47v0edthhttyqC6b0DYPAjMh169ZlW4yUcNNNN7Fs2bIWbd/73ve4+uqrsySRN9I5EzbTNMdf/IgpfcPIMR588MFsi2D4GAvkGoZh5BGm9A3DMPIIU/qGYRh5hCl9wzCMPMKT0heRsSKySUQ2i0irOrAi0kNElojIKhFZIyLnBduLROQJEVkrIhtF5K5Un4Bh+AGrp59Yn1TV0w+vR/+d73yHr371q/Tv379Vv+XLl3PttdfGvf+5c+eyY8eOpOV04q233uJb3/qW4zGbK7CmElelLyKFwIPAN4G+wCQR6RvR7R5gnqqWA5cD/xVsnwAcpqplwBDgOhHpmRrRjbxmzTyY3R8qSwL/18xL+yGtnn7qSUc9/SlTpvDaa685bgufrRsPiSj9WNdLNvFi6Q8DNqvqh6p6EHgOuDCijwJHBl93BnaEtXcSkXZAMXAQ+GfSUhv5zZp5sPAW2LsN0MD/hbckpfitnn726+n/z//8DwMGDGDgwIFcddVVoe/khhtu4Mwzz+SEE07g7bff5jvf+Q59+vRhypQpjud5xhlnRK1+uXjxYs4++2y2bt3K6aefzuDBgxk8eDDvvvtuqM/9999PWVkZAwcOZPr06bzwwgtUVVVxxRVXMGjQIGpra1m8eDHl5eWUlZXxne98J1RZNPJ6CaeyspKrrrqKs846i969e/Pwww+3km/FihWUl5fz4YcfOsqfEtym7AKXAo+Evb8K+HVEn67AWqAa+AIYEmwvIvCQ2AkcAKa6Hc8PU6iNzBNXGYZf9lO978jWf79MvIyC1dPPbj39devW6Te+8Y1QTfnmOvWTJ0/WiRMnalNTk86fP1+POOIIXbNmjTY2NurgwYN11apVqtq6Hr1TWY2dO3fqqFGjVDVQ6qG2tlZVVd9///1Q6YZXXnlFTz31VD1w4EALOUaOHKkrVqxQ1UDt/dLSUt20aZOqql511VU6e/bskBzh10s49913nw4YMEBramp0586dWlpaqtu3bw/V8F+2bJkOHjxYP/7441bXRiTpLsPgVLs1st7oJGCuqv6HiJwKPCki/QmMEhqB44CvAO+IyP+qaovHmIhMBaYC9OjRw4NIRl6ztzq+do9YPf3s1dN/8803ufTSS0PF6MIt9QsuuAARoaysjGOPPZaysjIA+vXrx9atW1sUOovFG2+8EVrlqr6+nmnTpvHee+9RWFgYqpH/v//7v1x99dWh83QaMWzatIlevXrxjW98A4DJkyfz4IMP8v3vfx9o+btH0rxmQHFxMWeeeSZ/+ctfKCkpYePGjUydOpU33niD4447ztP5JIoXpV8NdA97X8oh900z1wBjAVR1uYh0ALoA3wZeU9V64DMRWQZUAC2Uvqo+BDwEUFFR4a3QtZG/dC4NunYc2pMgnnr6Xoisp3/bbbcxbtw43nrrLSorKx0/E6ue/nXXXdei7wMPPOCrevqxWLRoEf/3f//HggUL+MlPfsL69etb1dOPdi5uMnvl1Vdf5bbbbgNg9uzZHHvssaxevZqmpqbQIiqx5Ggm1ncEsevsR7vGunbtSl1dHatWrUq70vfi018B9BaRXiLSnkCgdkFEn0+A0QAi0gfoQMCl8wlwlgToBJwCtHb4GUY8jL4XiiIWTCkqDrQngdXTz149/dGjRzNv3jx27doFwO7du5M+l3BUlTVr1oRGBXv37qVr164UFBTw5JNPhoKu55xzDo899lhoHd5mOcJ/35NOOomtW7eyefNmIFCieeTIkZ7kePnll6mrq2PXrl289dZboVLPJSUlLFq0iB/96Ee89dZbKTtvJ1yVvqo2ANOA14GNBLJ01ovIDBFpHk/eDlwrIquBZ4EpQR/Tg8DhwDoCD4/HVXVNGs7DyCcGXAYXzIHO3QEJ/L9gTqA9Cayefvbq6ffr14+7776bkSNHMnDgwJBFngiTJk3i1FNPZdOmTZSWlvLoo4+ycuVKysvLQ5b1jTfeyBNPPMEpp5zC+++/H7LOx44dy7hx46ioqGDQoEGhlNMpU6Zw/fXXM2jQIFSVxx9/nAkTJlBWVkZBQQHXX3+9oyy//e1v+e1vfxt6P2zYMM4//3xOOeUU/vVf/7WFVX/ssceycOFCbrrpJv785z8nfP5uiNtQJdNUVFSolUbNPzZu3EifPn2ydvytW7fyrW99K2cqbfqdpUuX8tRTT7VQiOnkpz/9KV//+tdbZA5lmsrKSg4//HB+8IMfJL0vp/tFRFaqaoXbZ63KpmEYGcepnn46CU9JzXdM6RsGVk/fSD/RgveZxpS+4Ru8ZE4Y7lg9/dwmWZe8FVwzfEGHDh3YtWtX0he0YeQyqsquXbtCKaaJYJa+4QtKS0uprq5m586d2RbFMHxNhw4dKC1NfE6KKX3DFxQVFUWdpWoYRuow945hGEYeYUrfMAwjjzClbxiGkUeY0jcMw8gjTOkbhmHkEZa9kwDzV21n1uub2LGnluNKirnj3BMZX94t22IZhmG4Yko/Tuav2s5dL66ltj5QinX7nlruenEtgCl+wzB8jyl9D4Rb9gUiNEbMGq2tb2TW65tM6RuG4XtM6bsQadlHKvxmduypzaRYhmEYCWGBXBdmvb4ppPBjcVxJsWsfwzCMbGNK3wUvFnxxUSF3nHtiBqQxDMNIDlP6LkSz4AtFEKBbSTE/u7jM/PmGYbQJTOm7cMe5J1JcVNii7dL277K25DY+6nAFyw67hfGFy6J82jAMw19YINeFZgu+OXtn8uF/4R59hHa1dYEOe7fBwlsCr5NcmNswDCPdeLL0RWSsiGwSkc0iMt1hew8RWSIiq0RkjYicF2y/QkTeC/trEpFBqT6JdDO+vBvLpp/FRzPPp7LT72nXWNeyQ30tLJ6RHeEMwzDiwNXSF5FC4EFgDFANrBCRBaq6IazbPcA8Vf2NiPQFXgF6qurTwNPB/ZQBL6vqe6k+iVQTc8bt3mrnD0Vrb4usmRd4iO2ths6lMPpeG8UYRo7gxdIfBmxW1Q9V9SDwHHBhRB8Fjgy+7gzscNjPJODZRAXNFM15+dv31KIcmnE7f9X2QIfOUVasidbe1lgzL+Cu2rsN0EPuqzXzsi2ZYRgpwIvS7wZsC3tfHWwLpxK4UkSqCVj5NzvsZyJtQOk75eU3z7gFAlZvUURGT1FxoD0XWDwj4K4Kx9xXhpEzeFH64tAWOS11EjBXVUuB84AnRSS0bxE5GahR1XWOBxCZKiJVIlKV7TVSo+Xlh9oHXAYXzIHO3QEJ/L9gTu64P/LBfWUYeYyX7J1qoHvY+1Jau2+uAcYCqOpyEekAdAE+C26/nBhWvqo+BDwEUFFR4VznIEMcV1LMdgfF3yJff8BluaPkI+lcGnTtOLQbhtHm8WLprwB6i0gvEWlPQIEviOjzCTAaQET6AB2AncH3BcAEArEA3+OUl59XM25z3X1lGHmOq6Wvqg0iMg14HSgEHlPV9SIyA6hS1QXA7cDDInIrAdfPFNVQZbIzgGpV/TA9p5BaIvPyc6JefjzZOM3tlr1jGDmJaJSqkdmioqJCq6qqsi1GS9pyCmNzNk54cLaoOLfiEIZhICIrVbXCrZ+VYXCjracwWjaO4cSaeTC7P1SWBP63levZSBpT+m60daVp2ThGJG3dkDGSwpS+G21daeb6ZDIjftq6IWMkhSl9N9q60rRsHCOStm7IGEmRl1U2Y9bWgZaB2+KvQGF7aDx4aHuE0nTdXzaxbBwjEpuLkdfkndKPXPO2ubYOBNM1I7NdandDQREUHwW1X7RSmq778wPJTiZry9lLRmtG3+uc0WWjv7wg79w7rrV1nPydTfXQvhNU7oFb17VQeK77a+tY0C/3yPVSIkZM8s7Sd62tE6e/03V/bZ1YQT9TEm2XXC4lYsQk75S+a22dOP2dnmr1tGUs6GfkKL6OxaWRvHPvuNbWiTPbJedr9bT17CXDcMB13YwcJu+U/vjybvzs4jK6lRQjQLeSYn52cdmhJ3yc/k7X/bV1LOXTyEFyPhYXA6u9k4fEPay17B3DD6TwOuw1fVGrRUEgsHjIRzPP97QPv7mHvNbeyTuffr6TUIqpBf2MTBOp4HufA6ufOZRUsHcbzL8RXv2hYyq1G8nG4tpEqnYU8sO9Y8WlQuTzsNZoIzilCVc95pxKXbubRFKJk43FteX7KPct/cjJVs0XB+Sl9ZrzKaZGYmTbhRd+fCkAbYzo4MENHUcqcbLrZkS7X7bvqaXX9EW+cPdEI/eVvuWZtyDnU0zTRbaVYjrJtmEUefxWCj8O4kglHl/eLWGlHO0+AlpkAzUfx0/kvnsnD/PM56/azvCZb9Jr+iKGz3yzRRpazqeYpoNcn5Wciqqbbi7UWNudju+IuHfJUCqx030USW19I7fPW+14H2aT3Lf086y4lFOA6Y7nV/PjhevZU1PPcSXFXDKkG0v+ttM3WQe+J9dHi8kaRm4jBbftXo5TVAwDvw0fvHGoEOLB/TELIaaTSPdQNOdTYzA70k+Wf+4r/UwUl/LR0N8pwFTfpHxRUw8ELr7fr9yeW3MJ0k2ujxaTNYzcHopu26MdXwpBm6LfU1m+78LdQ8NnvhnV3dNMc6A32/dd7iv9dJcWdrBiGl6+mZ8uWM8T+4dl3JL2EpCN9+LzWz5yxsn10WKyhpHbQ9Fte7TjuxWB81Eq8R3nnthihB0NPyRMeFL6IjIW+BVQCDyiqjMjtvcAngBKgn2mq+orwW0DgP8GjgSagKGqWpeyM/BCOi8OByumXWMd3216irkMy/iwLlaAqZlxBUu5s2YeVO46lAPdPGxui6Wj002ulyJO1jByeyhGteQLAj7+zqUtXTdtMFAe6e4pEAm5dsLxQ8KE64xcESkE3gfGANXACmCSqm4I6/MQsEpVfyMifYFXVLWniLQD/gpcpaqrReRoYI9q9PB8m5uRW1mCUzpZkwonfPl06H23kmKWTT8r7eJEKulIxhUsZWbRI3SUg47bgRZWVrRha6bOxzf4yIWXFWKdf+RoF1pa6k7bI4mw7NMyunT5DVN5TKf7sLioMK1u1VTOyB0GbFbVD4M7fg64ENgQ1kcJWPIAnYEdwdfnAGtUdTWAqu7yJn4bIooVs0OPbvk+Q8O68eXd6LbtD3T/6yy+qjv5VLowq2EiLzUMB+DOdvNiK3xo4W+1vP4gPnIlZBynQGzkbNhYlnrkSMIpDz/smkt0dBlTabsEk1M9ok12HkA68WLpXwqMVdXvBt9fBZysqtPC+nQF3gC+AnQCzlbVlSLyfWAI8FXgGOA5Vb3f4RhTgakAPXr0GPLxxx+n4twyg4MVU6PtmV7/XRY0jQi1ZcwydpCnobADP5XreWL/MLZ0uIICLxNdEKjcY5a+EUixdHLPhOPFB99MlNGx2zVXUlxEp8PaOSpRJ8u6qEA4vEM79tTUs7zD9/gXdrY+ZOfucOu6qMcsFKFJ1VdKOxpeLX0vefpOybGRv9gkYK6qlgLnAU+KSAGBkcQI4Irg/4tEZHSrnak+pKoVqlpxzDHHeBDJR0RU5awp7sq9OrWFwm+VB5/qshDh+3vpescYQ2Wn3/PRzPMp8Bp8DPazvP42SiqvMS9ZSvHk9buU6442itxTWx+1FHKsrDUFvqoOCh9C5xbtmI2q6Su9nKXyMF6UfjXQPex9KYfcN81cA8wDUNXlQAegS/Czb6vq56paA7wCDE5WaN8x4LLAMoqVe+j4w78x4qIbo5daTvVEn8j9RQuXhGdKRJZKjiQsSJnzpaNzkVRfY14NhfCHQyyF5lKu22uwM7zWjZu7cYd2cd4QPDcvx0xpbZ0sTvjz4t5pRyCQOxrYTiCQ+21VXR/W51Xgd6o6V0T6AIuBbgSyeRYTsPIPAq8Bs1V1UbTjZSOQm9GUxGhD5eAwM2X7i7V/pwqGbThzwogg1deYl0Bs+P7dArvN+4wSVHVLRginuRSyW568YwJDmEzxHjNpPZHq34gUBnJVtUFEpgGvE0jHfExV14vIDKBKVRcAtwMPi8itBFw/UzTwNPlCRH5J4EGhBLJ6oir8bJDxlMRUT/TxOpsxPL0wn4OS+UCqr7HIQKzbbFgvM5hjXINOQdCagw2hCYbhNFvobnnyC5pGQD38qP3z/Auft3rQeE25hBTV1snihD9PefrBnPtXItruDXu9ARge5bNPAU8lIWNaiVUiNS1KP9UTfRKdzWgkh59TOFNxjTmdX7gFGuv8U6DQIouhRUuBbI4tRSrtzsVFHDjYQH3jIcX9x8KRnHXhtKj3dfgxvVj+SemJLE74y/0ZuS5kPCUx1RN9Ep3NaCROtqtSupHsNebl/GKNFtOg0LykQDo9KBJ123qtrZOwnsjihL+8Xy4xKymJqbYS/Wx15iJp8MemnGSuiWTPz4tPPx2kcfJVKvRE5PEf6PsBQ7f8Z8ruW68+/bxX+tmYOWe0cVzyzH1JPA+BVJxfpg0RpwdNQREcdgTUfkFN8b9w74FLeOHgaaHN8dznyeqJTOiZVObp5x5h6WTj3zqX/xn6saUkxkMuLj8ZzzlFc1M015Lx23cSb3qgSx69J8LSmLl1XfpHnk7B47DlFDvW/p0Z8hDjCpaGNseTgpls6rKfllfMP5++g79y6Nr7WNaWfOAptqIih51nnnRM9Hr7fvdnJ0K85+Tkj4VDcyT89p3Eux5AWyww5yFI3FEOcme7eSw4eGjiZDw++fGFyxh/2AzoUA2HlULhvYC333fHntpAocN28zhOPmeHduH+hstYuGeE+4dTTP4p/Wg3wEvXw4tT0+JjX/GF+7NkAAAYVklEQVS1m/n+ht6pmQeQYqXrlLL61J8+CW1vlZqWiwuKxHtOcdaSyTrxZtOkuxx5OogWPI7gOGlZ/stz1csk77vJh/+FO+sPzRMolc+ZWfQIBQ1Cr+kpyPuPg/xz70S70LWRtMyQ3buN/ivvYcg//xh9Onc8roVULG0XhtOwM5IWw1A/LCiSavdSIucU7r7Qpvg/nyypcEfFctdk2j2TLF5mmtOyEGJc5USSvO/uLPpdq0KHHeUgPyj8XfrKPEQh/5S+F79kEkrU6eIoDg4rm2mhROP1t6ZY6Xod3jb3qyn+F8ftLdrT6fNPx/T1ZH3YqfCBx4PTdzD/Rvh5r4TKHqSDWOs0p4WIGlgUHwWF7Vt0aSjswCPtr0wsdpfkfdex9lPH9vCRR6Z8/Pmn9D1aBKmeIRs5rAwp23gtiCiK5FO6JHSDeR3eNve7v34iNdryZqrR9txfPzHwJl6FFC8pHukAztdEQREcPOBN5kwrVZegZasHYaRC7Nw9remTzS7D8OJodzy/mvIZb6T3IRA+OvnhR3Dhgy3Oud2F/0nlPT/mo5nns2z6WfG5UtJkGGSjBHv+Kf3IG0CirGifzAxZByJ/3JCyjdeCcFAwtdqefz84IaFholMVzUjCh8FP7B/G9PrvUt3UhSYVqpu6ML3+u8zdP4xe0xfx6Ys/ik8hxUs63EtOVqKId5kzrFQTqXo5v3E4w7+cQ6+6pxn+5RzmNzpOoE8JbhUvU+XKcB1NpNJFleyD3eHzNdqe+xtaypSJlbXyT+lDy4vhot+m1kqLopTDf9wWvsR4LYgIBfMpx/DDiNr9yaaiXXlKj6ipaceVFLOgaQQjDs7hhC+fZsTBOaFjxyxhG46bZR7LPZQuV0r4NdG+U8u6Ml5kjlQwkD4XV5xVL50s73T6j+NZpzlRMnJO4dfh4hmBhWISfbAnUoI9TeRf9k4kqc5UcNjfuq/dzMoNvRGn7J1E0uPCpsCfOn2R4zSauFLRIqavx8KtsNUO7UKpfO6+o2jWqluWRCbSCZMdTaQ7rTVaymgkwYdDputLeVmnGZJzZaTknGJVm40sKrd3G6x+JrkRXNh92xEYsWo7y7OwspYpfUh91cmI/Q0Flo2L0RcSfuhEu8HSNUx0q0lyf8Nl7mvwQnRr1S19MhPphMnWjkl3WmucVS+91JdKZXlxN8OgmfBrNN7jJ10zy+nBXPXooe21u1t/JsVpuPEYW6nElL4fSOKh43SDpXuYGH6xRtYkaVXC1q0MbyRerOx0l4ZOdjQR9Ry2BVwFiTyokqh66WYYpHt9WKeKl+HXaCLHT9rYcXoweyGTqclpIj99+jlEtle2cgoE/7FwJH+68O2oWRQryn7M8FeiZBtlOv3RiWQDszFlTSCY7SVNNUbQ0m3Jy3SUCBhf3o1l08/io5nn89595zDr0oFRr9FEjp/0Mp6JKu9MXodpIu8LrhnJE8/Q3G0B68mH/4V79Le0a6w79CEfloqOec7xrjTlRgqqesaSt1eUuFDzqlTpJtHjJ+WS8rriXDg+vA7DSdnKWUb2yehyjgkQj28yVjofwNz9w9jfvoEZnX4fmNDiwxIAru6ISJ97tGrsXq3NNCxKEk6m40KpOn5SPnEvwfCwKp1+vA4TxZS+z8n4co5pxkug7YWDp7G842iWVaZpPYMk8ZQ5Eh53iGqpxzGxJ42rLDnFhYoKhJqDDfSavsi9CF8ajp/29EWnhIA8WSvalL4PiGXJZ3w5xzSTiXS+dBN35kgigeHwwGzxVwIlBbwGw+MkWuC1efTlWoQvxcfP2Gg2T9eK9qT0RWQs8CsCC6M/oqozI7b3AJ4ASoJ9pqvqKyLSE9gINEdk/qSq16dG9NzAzZLP+HKOaSaRdD6/Ebc7wkuaaaSSD894qt0dcDUUH5U2V0NkRtae2taLkIeTasMjW+mL+Yir0heRQuBBYAxQDawQkQXBxdCbuQeYp6q/EZG+BBZR7xnctkVVB6VW7Pjws0/czZI/rqSYIf/8Y6s63CuPHJMliR2Io76/k1V5Zv1b3F7wu9D5PcDljDj3xoT2ny7Cr6HOxUUUFUrUFERHYlmVkYFfpxzxpvrATOEffpTEWXgj3iJ8EP895ud7MtfxYukPAzar6ocAIvIccCEQrvQVODL4ujOwI5VCJoPffeJulvwDfT+g/8pHKA6rw/3zokdY17cn4AOfdwKzT1tYdWvm0fDyo6FsnVL5nJmFj9CucCBwmS8WbYm8hvbU1lNUIHylYxF7auqTV1pec8ZjBG5TqUS9uuASzfP3+z3pmVgzen0cE/CSp98NCI8iVQfbwqkErhSRagJW/s1h23qJyCoReVtETk9G2ETw0zJlTkRzCTS3D93ynyGF30yxHAwsqOwHkq16uXhGy/RMCLxv/nw6qmrGSbSMo47t20Wt2BhXaWGvWThRAreprkMTbxG+eO8xv9+TnnCaO1H1aGpLfqcJL0pfHNoic9AmAXNVtRQ4D3hSRAqAvwM9VLUcuA14RkSOjPgsIjJVRKpEpGrnTg8Fu+LA7z5x10kmURRC097qzNUqj0Wy6YQu59fkg0Vb4r2G4lbCXrJwYgRuU61E4y3CF+/34/d70hNeRmcZNk684sW9Uw10D3tfSmv3zTXAWABVXS4iHYAuqvoZ8GWwfaWIbAG+AbSYfaWqDwEPQWByVgLnEZVs5yC74Zq5ECVdb0fT0S0USvi+Mkqy6YQu57ej6WhKCxwKuGVwZmS811DcGVdO2T1x5IinQ4nGE1iN9/vx+z3piWTnWGQRL5b+CqC3iPQSkfbA5cCCiD6fAKMBRKQP0AHYKSLHBAPBiMgJQG/gw1QJ74Wkp2tngPAp661cBR7qcGd1aJxInfHwkrUHD7Ra4Sj8/O5vuKzVoi2O+0/jal3xXkNxK2Gnsg/j/ysQtA2WVZjfODyqu8jNRZgOwt1XB75soKiwpUMg1vfTFu5JV7waHVKQnvLaSeBq6atqg4hMA14nkI75mKquF5EZQJWqLgBuBx4WkVsJuH6mqKqKyBnADBFpABqB61XVITUhfWQtBzhVRKT7VTcdzf0Nl7Woww1ZHBrHW/XSKVMlLB0x8vyaC7jd2W4epQW7oqc7pjHYG+81lJAlGyO7xy3wmenJTckGttv8PQney1tr8DfJQgJCNKz2TiZIYcphZFXLZrqVFLNsug+yedxwqSOT0PmloDZNKnGqL1RcVBhXIbzwbJwCERod7tPw7ySTKZBt/hpMFbGyd6TgkMIPJ43XpNXe8QsptkKzMmU9lbgEZhM6Px8Ee8NJ1pKNfGg4KXxoObrL5OSmnAjEpoJYcy8qS5zbfeDjN6WfblK8oEabHxq7BH4TOr8016ZJhGSUsFMg2IlY7qJ0Wv45EYhNNz68JpsxpZ9uErFCXdxBbXrKuoc6NHGfXyaWUEySeJSwF4s51ugn3ZOf2vxoMxP4+Jo0pZ9u4n3i+2AGarLEVHDpWO4wE0soJkG8SjiaJV0oQpOq60Mj3UX62vxoMxP4+Jq0QG66cVpQI9ZiDD4LSsZLKoKYKcEteJ7Bej7xBj6T/Q6zvSiKkR28BnJtucR0E+/Sez4LSsaLL6bYuy0v6GX5wRTi5K4ZV7CU39Vc65jDnewSmNnI2zfaDubeyQQRUf75q7Yza+abcc3A9UMAyAu+yOxwC56nOLjuRqS7ZlzBUmYWPULH5ppKDi68ZOI25nM3YmGWfoZxrcuSyAxXH+ELK9NttJTh0VTkDNQ72807pPCbSWGdlmRHCkZuY5Z+hnENsvk4AOQFX1iZbqOlDI+mWgU+C3Y5d0zhQ6dNZ3gZacWUfobx5P5ow8u4+SKzwy1dLgvpdC2U8OzkHzq2CImRKKb0M0w+TGzJupXpNlrK9mgqyYdOzixCYmQFS9nMML5JaTRakHHLOYmUUat9YzhhtXd8ii/cH22MdCvkrFjOSbjwUpEhZe6h/MWUfhbIuvujDZEyhRzDsk73DFYvxKOEk3URmnsov7GUTR8S1/qqOU5KJnu5TMbK9tyCeJdXTHYREl9MoDOyhil9n5HqRa7bOilRyC6Lq2d7bkG8SjjZPPxsP+SM7GLuHZ/hB1eDn/DqyojpHklHDf8kCZc3WipFLCWcjIswHzLIjOiYpe8zzApriRdXhuvoKEr++6d0odf0Rcx6fROXDOmWsRmskfJGI11KOCfWqDUSxpS+z8i2q8FveHFluLpHHEpb1Gp7/v3ghNBD4vcrt3PHuSeGFqcH0hZX8bJISjqVsJVpyG/MveMzfFHGwGe4uTJcR0cRk7E+pQv/Xj+hxeLy4S60dGe3xBq1CWQkhdIyyPIXT0pfRMYCvwIKgUdUdWbE9h7AE0BJsM90VX0lYvsGoFJVf5Ei2XMSy+OPH08+6rC8+FOj1JtvVsbpjqtEk9cmVxmZwFXpi0gh8CAwBqgGVojIAlXdENbtHmCeqv5GRPoCrwA9w7bPBl5NmdQ5jllh8RHv6MjtIZHuuIqN5oxs4sWnPwzYrKofqupB4Dngwog+ChwZfN0Z2NG8QUTGAx8C65MX1zBaE6+P2i2Qme64ivnUjWzixb3TDQgvCVgNnBzRpxJ4Q0RuBjoBZwOISCfghwRGCT9IVljDiEY8oyM3F1omLHEbzRnZwovSF4e2SJfoJGCuqv6HiJwKPCki/YEfA7NVdb+I026CBxCZCkwF6NGjhyfBDSMZYildi6sYuYwXpV8NdA97X0qY+ybINcBYAFVdLiIdgC4ERgSXisj9BIK8TSJSp6q/Dv+wqj4EPASBKpuJnIhhpJJ4LXErYGa0Fbwo/RVAbxHpBWwHLge+HdHnE2A0MFdE+gAdgJ2qenpzBxGpBPZHKnzDaOtYATOjLeEayFXVBmAa8DqwkUCWznoRmSEi44LdbgeuFZHVwLPAFPVboX4ja+R6ATkrYGa0JTzl6Qdz7l+JaLs37PUGYLjLPioTkM9o4+SDFWylM4y2hJVhMNJKPljBVjrDaEuY0jfSSj5YwVbAzGhLWO0dI634pYxvOrNrLMXTaEuY0jfSih9KDmQirmCTrYy2grl3jLTih5ID+RBXMAyvmKVvpJ1sW8H5EFcwDK+YpW/kPJZdYxiHMKVv5DyWXWMYhzD3jpHzWHaNYRzClL6RF2Q7rmAYfsHcO4ZhGHmEKX3DMIw8wtw7RpvDy+xaq29vGM6Y0jfaFF5m1+ZDZU/DSJScc+/keu32fMfL7FqbgWsY0ckpS98svNzHy+xam4FrGNHJKUvfLLzcx8vsWpuBaxjRySmlbxZe7uNldq3NwDWM6OSUe8cvtduN9OFldq3NwDWM6Ijf1i+vqKjQqqqqhD4b6dOHgIWX6VK+hmEYmUZEVqpqhVs/T+4dERkrIptEZLOITHfY3kNElojIKhFZIyLnBduHich7wb/VInJR/KfiHT/UbjcMw/Azrpa+iBQC7wNjgGpgBTBJVTeE9XkIWKWqvxGRvsArqtpTRDoCB1W1QUS6AquB41S1IdrxkrH0DcMw8pVUWvrDgM2q+qGqHgSeAy6M6KPAkcHXnYEdAKpaE6bgOwT7GYZhGFnCi9LvBmwLe18dbAunErhSRKqBV4CbmzeIyMkish5YC1wfy8o3DMMw0osXpS8ObZEW+yRgrqqWAucBT4pIAYCq/llV+wFDgbtEpEOrA4hMFZEqEanauXNnfGcQyZp5MLs/VJYE/q+Zl9z+DMMwcggvSr8a6B72vpSg+yaMa4B5AKq6nIArp0t4B1XdCBwA+kceQFUfUtUKVa045phjvEsfyZp5sPAW2LsN0MD/hbeY4jcMwwjiRemvAHqLSC8RaQ9cDiyI6PMJMBpARPoQUPo7g59pF2w/HjgR2Joi2VuzeAbUR+Tp19cG2g3DMAz3yVnBzJtpwOtAIfCYqq4XkRlAlaouAG4HHhaRWwm4fqaoqorICGC6iNQDTcCNqvp52s5mb3V87YZhGHmGpxm5qvoKgQBteNu9Ya83AMMdPvck8GSSMnqnc2nQtePQbhiGYeRW7R1G3wtFESUXiooD7YZhGEaOKf0Bl8EFc6Bzd0AC/y+YE2g3DMMwcqvgGhBQ8KbkDcMwHMktS98wDMOIiSl9wzCMPMKUvmEYRh5hSt8wDCOPMKVvGIaRR5jSNwzDyCNM6RuGYeQRpvQNwzDyCFP6hmEYeYQpfcMwjDzClL5hGEYeYUrfMAwjjzClbxiGkUeY0jcMw8gjTOkbhmHkEab0DcMw8ghT+oZhGHmEJ6UvImNFZJOIbBaR6Q7be4jIEhFZJSJrROS8YPsYEVkpImuD/89K9QkYhmEY3nFdLlFECoEHgTFANbBCRBao6oawbvcA81T1NyLSF3gF6Al8DlygqjtEpD/wOtAtxedgGIZheMSLpT8M2KyqH6rqQeA54MKIPgocGXzdGdgBoKqrVHVHsH090EFEDktebMMwDCMRvCj9bsC2sPfVtLbWK4ErRaSagJV/s8N+LgFWqeqXkRtEZKqIVIlI1c6dOz0JbhiGYcSPF6UvDm0a8X4SMFdVS4HzgCdFJLRvEekH/By4zukAqvqQqlaoasUxxxzjTXLDMAwjbrwo/Wqge9j7UoLumzCuAeYBqOpyoAPQBUBESoGXgP+nqluSFdgwDMNIHC9KfwXQW0R6iUh74HJgQUSfT4DRACLSh4DS3ykiJcAi4C5VXZY6sQ3DMIxEcFX6qtoATCOQebORQJbOehGZISLjgt1uB64VkdXAs8AUVdXg574O/KuIvBf8+2pazsQwDMNwRQK62T9UVFRoVVVVtsUwDMNoU4jISlWtcOtnM3INwzDyCFP6hmEYeYQpfcMwjDzClL5hGEYeYUrfMAwjjzClbxiGkUeY0jcMw8gjTOkbhmHkEab0DcMw8gjfzcgVkZ3AxynYVRcCi7j4Gb/LaPIlj99lNPmSxy8yHq+qrmWKfaf0U4WIVHmZkpxN/C6jyZc8fpfR5EuetiBjOObeMQzDyCNM6RuGYeQRuaz0H8q2AB7wu4wmX/L4XUaTL3nagowhctanbxiGYbQmly19wzAMI4KcVPoiMlZENonIZhGZnm15AETkMRH5TETWhbUdJSJ/FJEPgv+/kkX5uovIEhHZKCLrReR7fpJRRDqIyF9EZHVQvh8H23uJyJ+D8v0uuKRn1hCRQhFZJSJ/8Kl8W0VkbXAVu6pgmy9+46AsJSLygoj8LXgtnuoX+UTkxLAVAN8TkX+KyPf9Ip9Xck7pi0gh8CDwTaAvMElE+mZXKgDmAmMj2qYDi1W1N7A4+D5bNAC3q2of4BTgpuD35hcZvwTOUtWBwCBgrIicAvwcmB2U7wvgmizJ18z3CCwr2ozf5AM4U1UHhaUZ+uU3BvgV8JqqngQMJPBd+kI+Vd0U/N4GAUOAGuAlv8jnGVXNqT/gVOD1sPd3EViY3Q+y9QTWhb3fBHQNvu4KbMq2jGGyvQyM8aOMQEfgr8DJBCbFtHP67bMgVymBm/4s4A+A+Em+oAxbgS4Rbb74jYEjgY8Ixhr9Jl+ETOcAy/wqX6y/nLP0gW7AtrD31cE2P3Ksqv4dIPjfF4vGi0hPoBz4Mz6SMeg6eQ/4DPgjsAXYo6oNwS7Z/q0fAO4EmoLvj8Zf8gEo8IaIrBSRqcE2v/zGJwA7gceDLrJHRKSTj+QL53Lg2eBrP8oXlVxU+uLQZilKHhGRw4HfA99X1X9mW55wVLVRA0PrUmAY0MepW2alCiAi3wI+U9WV4c0OXbN9LQ5X1cEE3J83icgZWZYnnHbAYOA3qloOHMCHrpJgXGYc8Hy2ZUmEXFT61UD3sPelwI4syeLGP0SkK0Dw/2fZFEZEiggo/KdV9cVgs69kBFDVPcBbBGIPJSLSLrgpm7/1cGCciGwFniPg4nkA/8gHgKruCP7/jIA/ehj++Y2rgWpV/XPw/QsEHgJ+ka+ZbwJ/VdV/BN/7Tb6Y5KLSXwH0DmZNtCcwDFuQZZmisQCYHHw9mYAfPSuIiACPAhtV9Zdhm3who4gcIyIlwdfFwNkEgnxLgEuzLZ+q3qWqparak8A196aqXuEX+QBEpJOIHNH8moBfeh0++Y1V9VNgm4icGGwaDWzAJ/KFMYlDrh3wn3yxyXZQIU1BlvOA9wn4fO/OtjxBmZ4F/g7UE7BoriHg810MfBD8f1QW5RtBwPWwBngv+HeeX2QEBgCrgvKtA+4Ntp8A/AXYTGC4fZgPfutRwB/8Jl9QltXBv/XN94ZffuOgLIOAquDvPB/4is/k6wjsAjqHtflGPi9/NiPXMAwjj8hF945hGIYRBVP6hmEYeYQpfcMwjDzClL5hGEYeYUrfMAwjjzClbxiGkUeY0jcMw8gjTOkbhmHkEf8flxKksD9yfA0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1559e39bf98>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_results = [None,]*len(actor_fns)\n",
    "#print(total_results)\n",
    "for img_fn in info_dict.keys():\n",
    "    #print(img_fn)\n",
    "    for actor_fn in info_dict[img_fn].keys():\n",
    "        #print(actor_fn)\n",
    "        if total_results[actor_fns.index(actor_fn)] is None:\n",
    "            print(torch.Tensor(info_dict[img_fn][actor_fn]).shape)\n",
    "            total_results[actor_fns.index(actor_fn)] = torch.Tensor(info_dict[img_fn][actor_fn])\n",
    "        else:\n",
    "            total_results[actor_fns.index(actor_fn)] += torch.Tensor(info_dict[img_fn][actor_fn])\n",
    "        \n",
    "#total_results / len(info_dict.keys())\n",
    "for actor_fn in actor_fns:\n",
    "    plt.scatter(x=np.arange(75), y=total_results[actor_fns.index(actor_fn)] / len(info_dict.keys()), label=actor_fn)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "\n",
    "annot_dir = 'VOC2012/Annotations/'\n",
    "\n",
    "annotations = {}\n",
    "\n",
    "for filename in os.listdir(annot_dir):\n",
    "    tree = ET.parse(annot_dir + filename)\n",
    "    root = tree.getroot()\n",
    "    name = filename.replace('.xml','')\n",
    "    #print(name)\n",
    "    objects_ar = []\n",
    "    for obj in root.findall('object'):\n",
    "        obj_dict = {}\n",
    "        for obj_name in obj.findall('name'):\n",
    "            #print(obj_name.text, classes.index(obj_name.text))\n",
    "            obj_dict['name'] = obj_name.text\n",
    "            obj_dict['ind'] = classes.index(obj_name.text)\n",
    "        for size in obj.findall('size'):\n",
    "            for width in bndbox.findall('width'):\n",
    "                obj_dict['original_width'] = int(width)\n",
    "            for height in bndbox.findall('height'):\n",
    "                obj_dict['original_height'] = int(height)\n",
    "        for bndbox in obj.findall('bndbox'):\n",
    "            for bnd in bndbox.findall('xmin'):\n",
    "                obj_dict['xmin'] = int(bnd.text)\n",
    "            for bnd in bndbox.findall('xmax'):\n",
    "                obj_dict['xmax'] = int(bnd.text)\n",
    "            for bnd in bndbox.findall('ymin'):\n",
    "                obj_dict['ymin'] = int(bnd.text)\n",
    "            for bnd in bndbox.findall('ymax'):\n",
    "                obj_dict['ymax'] = int(bnd.text)\n",
    "        objects_ar.append(obj_dict)\n",
    "    annotations[name] = {}\n",
    "    annotations[name]['objects'] = objects_ar\n",
    "#annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'person', 'ind': 15, 'xmin': 174, 'xmax': 349, 'ymin': 101, 'ymax': 351}\n",
      "tensor([ 8.8358, -1.1193, -1.1473, -1.0111, -0.2464, -0.9082, -0.8387,  0.2525,\n",
      "        -0.9701,  0.5917, -1.4688,  0.9092, -0.7508, -1.1490, -1.1254,  2.9162,\n",
      "        -0.4624, -1.4968, -0.1229, -0.2435, -0.3459], grad_fn=<MeanBackward1>)\n",
      "true  15 pred  tensor(15)\n",
      "{'name': 'aeroplane', 'ind': 1, 'xmin': 104, 'xmax': 375, 'ymin': 78, 'ymax': 183}\n",
      "tensor([ 8.7491, -1.1205, -1.1376, -1.0121, -0.2541, -0.9077, -0.8070,  0.2840,\n",
      "        -0.9535,  0.5712, -1.4323,  0.9153, -0.7517, -1.1376, -1.1121,  2.8018,\n",
      "        -0.4392, -1.4708, -0.1195, -0.2411, -0.3279], grad_fn=<MeanBackward1>)\n",
      "true  1 pred  tensor(15)\n",
      "{'name': 'aeroplane', 'ind': 1, 'xmin': 133, 'xmax': 197, 'ymin': 88, 'ymax': 123}\n",
      "tensor([ 8.6407, -1.1382, -1.1511, -0.9850, -0.2681, -0.8906, -0.8075,  0.2268,\n",
      "        -0.9341,  0.5850, -1.4160,  0.9107, -0.7079, -1.1149, -1.1362,  2.8579,\n",
      "        -0.4387, -1.4733, -0.1194, -0.2243, -0.3136], grad_fn=<MeanBackward1>)\n",
      "true  1 pred  tensor(15)\n",
      "{'name': 'person', 'ind': 15, 'xmin': 195, 'xmax': 213, 'ymin': 180, 'ymax': 229}\n",
      "tensor([ 8.7063, -1.0997, -1.1407, -0.9911, -0.2431, -0.8907, -0.8087,  0.2535,\n",
      "        -0.9490,  0.5593, -1.4345,  0.9097, -0.7252, -1.1315, -1.1205,  2.8215,\n",
      "        -0.4346, -1.4722, -0.1393, -0.2320, -0.3361], grad_fn=<MeanBackward1>)\n",
      "true  15 pred  tensor(15)\n",
      "{'name': 'person', 'ind': 15, 'xmin': 26, 'xmax': 44, 'ymin': 189, 'ymax': 238}\n",
      "tensor([ 8.6581, -1.1143, -1.1336, -0.9855, -0.2685, -0.8648, -0.8177,  0.2576,\n",
      "        -0.9505,  0.5902, -1.4487,  0.9137, -0.7400, -1.1350, -1.1298,  2.8553,\n",
      "        -0.4067, -1.4812, -0.1330, -0.2344, -0.3334], grad_fn=<MeanBackward1>)\n",
      "true  15 pred  tensor(15)\n",
      "{'name': 'aeroplane', 'ind': 1, 'xmin': 9, 'xmax': 499, 'ymin': 107, 'ymax': 263}\n",
      "tensor([ 8.6834, -1.0560, -1.1116, -0.9897, -0.2274, -0.8838, -0.7926,  0.2839,\n",
      "        -0.9584,  0.5534, -1.4342,  0.8521, -0.7473, -1.1203, -1.0874,  2.8089,\n",
      "        -0.4530, -1.4844, -0.1728, -0.2276, -0.3235], grad_fn=<MeanBackward1>)\n",
      "true  1 pred  tensor(15)\n",
      "{'name': 'aeroplane', 'ind': 1, 'xmin': 421, 'xmax': 482, 'ymin': 200, 'ymax': 226}\n",
      "tensor([ 8.7353, -1.0923, -1.1417, -1.0060, -0.2455, -0.9049, -0.8074,  0.2787,\n",
      "        -0.9532,  0.5806, -1.4448,  0.8761, -0.7409, -1.1420, -1.1281,  2.8234,\n",
      "        -0.4328, -1.4862, -0.1245, -0.2198, -0.3237], grad_fn=<MeanBackward1>)\n",
      "true  1 pred  tensor(15)\n",
      "{'name': 'aeroplane', 'ind': 1, 'xmin': 325, 'xmax': 411, 'ymin': 188, 'ymax': 223}\n",
      "tensor([ 8.5833, -1.0996, -1.1028, -1.0137, -0.2497, -0.8815, -0.7994,  0.2852,\n",
      "        -0.9289,  0.6019, -1.4452,  0.9256, -0.7261, -1.1412, -1.0877,  2.7878,\n",
      "        -0.4487, -1.4765, -0.1137, -0.2351, -0.3348], grad_fn=<MeanBackward1>)\n",
      "true  1 pred  tensor(15)\n",
      "{'name': 'tvmonitor', 'ind': 20, 'xmin': 156, 'xmax': 344, 'ymin': 89, 'ymax': 279}\n",
      "tensor([ 8.7307, -1.1199, -1.1481, -0.9907, -0.2602, -0.9014, -0.8136,  0.2681,\n",
      "        -0.9484,  0.5617, -1.4316,  0.9145, -0.7287, -1.1262, -1.1460,  2.8385,\n",
      "        -0.4306, -1.4633, -0.1226, -0.2376, -0.3459], grad_fn=<MeanBackward1>)\n",
      "true  20 pred  tensor(15)\n",
      "{'name': 'train', 'ind': 19, 'xmin': 263, 'xmax': 500, 'ymin': 32, 'ymax': 295}\n",
      "tensor([ 8.5971, -1.1076, -1.1339, -1.0049, -0.2523, -0.8724, -0.7949,  0.2522,\n",
      "        -0.9403,  0.6036, -1.4441,  0.8965, -0.7215, -1.1369, -1.1055,  2.8445,\n",
      "        -0.4334, -1.4827, -0.1137, -0.2221, -0.3274], grad_fn=<MeanBackward1>)\n",
      "true  19 pred  tensor(15)\n",
      "{'name': 'train', 'ind': 19, 'xmin': 1, 'xmax': 235, 'ymin': 36, 'ymax': 299}\n",
      "tensor([ 8.6995, -1.1169, -1.1342, -1.0033, -0.2672, -0.8904, -0.8156,  0.2548,\n",
      "        -0.9432,  0.5856, -1.4437,  0.9173, -0.7261, -1.1294, -1.1094,  2.8637,\n",
      "        -0.4461, -1.4876, -0.1301, -0.2413, -0.3331], grad_fn=<MeanBackward1>)\n",
      "true  19 pred  tensor(15)\n",
      "{'name': 'boat', 'ind': 4, 'xmin': 274, 'xmax': 437, 'ymin': 11, 'ymax': 279}\n",
      "tensor([ 8.6412, -1.1323, -1.1102, -0.9864, -0.3051, -0.8759, -0.8007,  0.2618,\n",
      "        -0.9377,  0.5411, -1.4088,  0.8619, -0.7081, -1.0946, -1.0929,  2.8478,\n",
      "        -0.3886, -1.4495, -0.1619, -0.2447, -0.3677], grad_fn=<MeanBackward1>)\n",
      "true  4 pred  tensor(15)\n",
      "{'name': 'boat', 'ind': 4, 'xmin': 184, 'xmax': 281, 'ymin': 214, 'ymax': 252}\n",
      "tensor([ 8.7521, -1.1150, -1.1370, -0.9825, -0.2456, -0.8848, -0.8324,  0.2608,\n",
      "        -0.9447,  0.5756, -1.4464,  0.9142, -0.7435, -1.1464, -1.1362,  2.7971,\n",
      "        -0.4141, -1.4721, -0.1438, -0.2514, -0.3101], grad_fn=<MeanBackward1>)\n",
      "true  4 pred  tensor(15)\n",
      "{'name': 'dog', 'ind': 12, 'xmin': 123, 'xmax': 379, 'ymin': 115, 'ymax': 275}\n",
      "tensor([ 8.5073, -1.1151, -1.1161, -0.9772, -0.2813, -0.8664, -0.8268,  0.2510,\n",
      "        -0.9045,  0.5822, -1.4149,  0.9315, -0.7014, -1.0980, -1.1032,  2.8602,\n",
      "        -0.4508, -1.4379, -0.1158, -0.2577, -0.3562], grad_fn=<MeanBackward1>)\n",
      "true  12 pred  tensor(15)\n",
      "{'name': 'chair', 'ind': 9, 'xmin': 75, 'xmax': 428, 'ymin': 1, 'ymax': 375}\n",
      "tensor([ 8.6136, -1.0931, -1.1236, -0.9996, -0.2332, -0.8696, -0.7838,  0.2870,\n",
      "        -0.9620,  0.5928, -1.4426,  0.9626, -0.7692, -1.1556, -1.1045,  2.7997,\n",
      "        -0.4548, -1.4797, -0.1375, -0.2117, -0.3229], grad_fn=<MeanBackward1>)\n",
      "true  9 pred  tensor(15)\n",
      "{'name': 'bird', 'ind': 3, 'xmin': 27, 'xmax': 266, 'ymin': 45, 'ymax': 375}\n",
      "tensor([ 8.8275, -1.1384, -1.1540, -1.0341, -0.2570, -0.9056, -0.8139,  0.2692,\n",
      "        -0.9581,  0.5886, -1.4423,  0.8890, -0.7444, -1.1458, -1.1322,  2.8421,\n",
      "        -0.4179, -1.4858, -0.1121, -0.2411, -0.3340], grad_fn=<MeanBackward1>)\n",
      "true  3 pred  tensor(15)\n",
      "{'name': 'tvmonitor', 'ind': 20, 'xmin': 251, 'xmax': 475, 'ymin': 28, 'ymax': 267}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-e70a0e8c1bce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m#plt.show()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_just_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'true '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ind'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pred '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_dir = 'VOC2012/JPEGImages/'\n",
    "for img_name in annotations.keys():\n",
    "    img_fn = img_dir + img_name + '.jpg'\n",
    "    full_img = cv2.imread(img_fn, cv2.IMREAD_COLOR)[:,:,::-1]\n",
    "    annotation = annotations[img_name]\n",
    "    #print(img_fn)\n",
    "    #plt.imshow(full_img)\n",
    "    #plt.show()\n",
    "    for obj in annotation['objects']:\n",
    "        print(obj)\n",
    "        img_just_obj = full_img[obj['ymin']:obj['ymax'], obj['xmin']:obj['xmax'], :]\n",
    "        #plt.imshow(img_just_obj)\n",
    "        #plt.show()\n",
    "        predictions = classify(img_just_obj)\n",
    "        print(predictions)\n",
    "        print('true ', obj['ind'], 'pred ', torch.argmax(predictions[1:]) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to C:\\Users\\Peter/.cache\\torch\\checkpoints\\resnet101-5d3b4d8f.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fea2105ac1942f0a6af5ff1ec42d51d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=178728960), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/fcn_resnet101_coco-7ecb50ca.pth\" to C:\\Users\\Peter/.cache\\torch\\checkpoints\\fcn_resnet101_coco-7ecb50ca.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a39c98243a643bdbfd445b849a79e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=217800805), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models.segmentation as segmentation\n",
    "\n",
    "resnet = segmentation.fcn_resnet101(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on FCN in module torchvision.models.segmentation.fcn object:\n",
      "\n",
      "class FCN(torchvision.models.segmentation._utils._SimpleSegmentationModel)\n",
      " |  Implements a Fully-Convolutional Network for semantic segmentation.\n",
      " |  \n",
      " |  Arguments:\n",
      " |      backbone (nn.Module): the network used to compute the features for the model.\n",
      " |          The backbone should return an OrderedDict[Tensor], with the key being\n",
      " |          \"out\" for the last feature map used, and \"aux\" if an auxiliary classifier\n",
      " |          is used.\n",
      " |      classifier (nn.Module): module that takes the \"out\" element returned from\n",
      " |          the backbone and returns a dense prediction.\n",
      " |      aux_classifier (nn.Module, optional): auxiliary classifier used during training\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      FCN\n",
      " |      torchvision.models.segmentation._utils._SimpleSegmentationModel\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods inherited from torchvision.models.segmentation._utils._SimpleSegmentationModel:\n",
      " |  \n",
      " |  __init__(self, backbone, classifier, aux_classifier=None)\n",
      " |      Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      " |  \n",
      " |  forward(self, x)\n",
      " |      Defines the computation performed at every call.\n",
      " |      \n",
      " |      Should be overridden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torchvision.models.segmentation._utils._SimpleSegmentationModel:\n",
      " |  \n",
      " |  __constants__ = ['aux_classifier']\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__(self, *input, **kwargs)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      __dir__() -> list\n",
      " |      default dir() implementation\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_module(self, name, module)\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self, fn)\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`nn-init-doc`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.data.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  buffers(self, recurse=True)\n",
      " |      Returns an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf.data), buf.size())\n",
      " |          <class 'torch.FloatTensor'> (20L,)\n",
      " |          <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self)\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self)\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self, device=None)\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self)\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self)\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  extra_repr(self)\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should reimplement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  float(self)\n",
      " |      Casts all floating point parameters and buffers to float datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  half(self)\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict, strict=True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing the missing keys\n",
      " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
      " |  \n",
      " |  modules(self)\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |  \n",
      " |  named_buffers(self, prefix='', recurse=True)\n",
      " |      Returns an iterator over module buffers, yielding both the\n",
      " |      name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>    if name in ['running_var']:\n",
      " |          >>>        print(buf.size())\n",
      " |  \n",
      " |  named_children(self)\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo=None, prefix='')\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |  \n",
      " |  named_parameters(self, prefix='', recurse=True)\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse=True)\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param.data), param.size())\n",
      " |          <class 'torch.FloatTensor'> (20L,)\n",
      " |          <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook)\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to module\n",
      " |      inputs are computed. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> Tensor or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` may be tuples if the\n",
      " |      module has multiple inputs or outputs. The hook should not modify its\n",
      " |      arguments, but it can optionally return a new gradient with respect to\n",
      " |      input that will be used in place of :attr:`grad_input` in subsequent\n",
      " |      computations.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |      \n",
      " |      .. warning ::\n",
      " |      \n",
      " |          The current implementation will not have the presented behavior\n",
      " |          for complex :class:`Module` that perform many operations.\n",
      " |          In some failure cases, :attr:`grad_input` and :attr:`grad_output` will only\n",
      " |          contain the gradients for a subset of the inputs and outputs.\n",
      " |          For such :class:`Module`, you should use :func:`torch.Tensor.register_hook`\n",
      " |          directly on a specific input or output to get the required gradients.\n",
      " |  \n",
      " |  register_buffer(self, name, tensor)\n",
      " |      Adds a persistent buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the persistent state.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor): buffer to be registered.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook)\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None or modified output\n",
      " |      \n",
      " |      The hook can modify the output. It can modify the input inplace but\n",
      " |      it will not have effect on forward since this is called after\n",
      " |      :func:`forward` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook)\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None or modified input\n",
      " |      \n",
      " |      The hook can modify the input. User can either return a tuple or a\n",
      " |      single modified value in the hook. We will wrap the value into a tuple\n",
      " |      if a single value is returned(unless that value is already a tuple).\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_parameter(self, name, param)\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter): parameter to be added to the module.\n",
      " |  \n",
      " |  requires_grad_(self, requires_grad=True)\n",
      " |      Change if autograd should record operations on parameters in this\n",
      " |      module.\n",
      " |      \n",
      " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
      " |      in-place.\n",
      " |      \n",
      " |      This method is helpful for freezing part of the module for finetuning\n",
      " |      or training parts of a model individually (e.g., GAN training).\n",
      " |      \n",
      " |      Args:\n",
      " |          requires_grad (bool): whether autograd should record operations on\n",
      " |                                parameters in this module. Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  share_memory(self)\n",
      " |  \n",
      " |  state_dict(self, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing a whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point desired :attr:`dtype` s. In addition, this method will\n",
      " |      only cast the floating point parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point type of\n",
      " |              the floating point parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |  \n",
      " |  train(self, mode=True)\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
      " |                       mode (``False``). Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self, dst_type)\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self)\n",
      " |      Sets gradients of all model parameters to zero.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  dump_patches = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# help(resnet)\n",
    "help(resnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([440, 440])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "input_image = Image.open('image/clint.jpg')\n",
    "input_image = cv2.imread('image/clint.jpg', cv2.IMREAD_COLOR)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "output = resnet(input_batch)['out'][0]\n",
    "output_predictions = output.argmax(0)\n",
    "output_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 440, 440])\n",
      "FCNHead(\n",
      "  (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "torch.Size([1, 21, 55, 55])\n",
      "tensor([[13.3556, 14.3556, 12.1097,  ..., 13.0071, 15.1190, 12.7221],\n",
      "        [13.1595, 15.0648, 12.5816,  ..., 16.7486, 16.2568, 14.2603],\n",
      "        [12.5285, 13.7900, 12.7179,  ..., 15.3280, 16.6753, 13.6351],\n",
      "        ...,\n",
      "        [12.3391, 13.1705, 11.2667,  ..., 10.6370,  9.3852,  7.3976],\n",
      "        [11.9025, 12.0127, 10.0946,  ..., 10.3399,  8.7669,  7.2733],\n",
      "        [11.8392, 10.0809,  9.8875,  ...,  9.1893,  8.2898,  7.2679]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[ 1.7355e-01, -1.3869e-03, -8.1726e-01,  ...,  9.6078e-01,\n",
      "          1.9075e+00,  2.7704e+00],\n",
      "        [ 4.7776e-01,  8.8657e-02, -9.1564e-01,  ...,  7.3847e-01,\n",
      "          2.1261e+00,  2.8513e+00],\n",
      "        [ 5.9492e-01,  3.7156e-01, -4.8434e-01,  ...,  2.9457e-01,\n",
      "          1.6183e+00,  2.6276e+00],\n",
      "        ...,\n",
      "        [-1.3298e+00, -1.4390e+00, -5.2770e-01,  ..., -1.6610e+00,\n",
      "         -1.7378e+00, -1.6440e+00],\n",
      "        [-2.0991e+00, -2.1612e+00, -1.2898e+00,  ..., -7.9610e-01,\n",
      "         -4.3722e-01, -7.4418e-01],\n",
      "        [-1.6735e+00, -2.1403e+00, -1.5293e+00,  ...,  8.0640e-01,\n",
      "         -6.9803e-01, -4.0966e-02]], grad_fn=<SliceBackward>)\n",
      "tensor([[-2.3563, -2.5275, -2.0663,  ..., -2.4574, -2.3819, -2.0250],\n",
      "        [-2.0686, -2.3633, -1.9041,  ..., -2.6518, -2.0251, -2.7058],\n",
      "        [-2.5798, -2.4114, -2.4211,  ..., -2.3320, -2.0557, -1.9851],\n",
      "        ...,\n",
      "        [-0.6986, -1.0225, -0.6983,  ...,  0.4514,  0.8385, -0.0297],\n",
      "        [-0.9879, -1.1584, -0.9381,  ..., -0.0682,  0.6369, -0.5128],\n",
      "        [-0.7072, -0.8817, -0.9165,  ...,  0.0095,  1.0208, -0.2616]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[-0.8874, -0.7398, -0.6975,  ..., -1.1225, -1.7890, -1.7347],\n",
      "        [-0.6767, -0.5282, -0.6865,  ..., -1.3846, -1.4459, -1.6313],\n",
      "        [-0.6381, -0.4738, -0.6454,  ..., -0.9136, -1.5090, -1.3107],\n",
      "        ...,\n",
      "        [-0.3244,  0.0797, -0.7220,  ..., -1.1848, -1.2683, -0.8355],\n",
      "        [ 0.2074,  0.2328, -0.4971,  ..., -1.1470, -1.2963, -0.5033],\n",
      "        [-0.8590, -0.0475, -0.6909,  ..., -1.5686, -1.4979, -1.3058]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[ 0.7942,  0.8360,  0.0838,  ...,  2.0984,  1.8331,  2.2092],\n",
      "        [-0.0944,  0.1545, -0.0462,  ...,  0.9871,  2.1281,  2.0777],\n",
      "        [-0.3576, -0.1725,  0.0534,  ...,  0.0676,  1.0808,  0.6266],\n",
      "        ...,\n",
      "        [ 0.8936,  0.4484,  0.7939,  ...,  1.9045,  2.0988,  2.6159],\n",
      "        [ 1.2736,  0.9514,  1.0923,  ...,  2.8018,  3.3344,  2.6504],\n",
      "        [ 0.0837, -0.0439, -0.0995,  ...,  2.2850,  2.1315,  1.8474]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[-0.8209, -1.2521, -1.0609,  ..., -0.6010, -1.3747, -0.9742],\n",
      "        [-1.4845, -1.5388, -1.0421,  ..., -1.3855, -1.7810, -2.0707],\n",
      "        [-1.8339, -1.9149, -1.5833,  ..., -1.2539, -1.6156, -1.6075],\n",
      "        ...,\n",
      "        [-2.2513, -2.6685, -2.2277,  ..., -1.3874, -2.6517, -1.7682],\n",
      "        [-1.7149, -1.3766, -1.5842,  ..., -1.2851, -2.3431, -1.6885],\n",
      "        [-1.1035, -0.3841, -0.7681,  ..., -1.4604, -1.7117, -1.6109]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[-0.7591, -0.5593, -1.4324,  ...,  0.0283,  1.0456,  2.0311],\n",
      "        [-1.1020, -1.0806, -1.6153,  ..., -1.1467,  0.7737,  1.4125],\n",
      "        [-0.5824, -0.9505, -1.5937,  ..., -2.1358, -1.0396, -0.4768],\n",
      "        ...,\n",
      "        [-2.9217, -3.0627, -1.9832,  ..., -2.4587, -1.9841, -1.6167],\n",
      "        [-1.8134, -2.3405, -1.0294,  ..., -2.6009, -1.7764, -1.4761],\n",
      "        [-1.2804, -1.4012, -0.7980,  ..., -2.7707, -2.3701, -1.3958]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[ 1.4488,  1.2853,  0.9541,  ...,  1.0740,  2.3017,  1.2599],\n",
      "        [ 1.6029,  1.3234,  0.6790,  ...,  1.4203,  2.2302,  1.4025],\n",
      "        [ 2.0342,  1.2595,  0.8202,  ...,  1.5402,  1.9451,  1.4436],\n",
      "        ...,\n",
      "        [-0.7820, -1.0541,  0.0540,  ...,  2.8660,  2.1937,  2.3358],\n",
      "        [-0.2693, -1.0930,  0.2905,  ...,  2.9884,  2.1367,  2.1217],\n",
      "        [ 0.1816, -0.2302,  0.5457,  ...,  2.2562,  1.3117,  1.2838]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[-2.3393, -2.1677, -1.4179,  ..., -0.8558, -1.8880, -1.5950],\n",
      "        [-1.9447, -2.0016, -1.3628,  ..., -1.1724, -2.6460, -2.8739],\n",
      "        [-1.2131, -1.5968, -1.0163,  ...,  0.1759, -1.4716, -0.8115],\n",
      "        ...,\n",
      "        [-0.7226, -0.6057, -1.2503,  ..., -3.6412, -4.1327, -3.1103],\n",
      "        [-0.9648, -1.0991, -1.2942,  ..., -4.0656, -3.9411, -3.4642],\n",
      "        [-0.9059, -0.2113, -0.5176,  ..., -3.8714, -3.9948, -3.3552]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[-0.4680, -0.7910,  0.5793,  ..., -0.7521, -1.3857, -1.6152],\n",
      "        [-0.4730, -0.7962,  0.9351,  ..., -0.7836, -1.4580, -1.7969],\n",
      "        [-1.1668, -1.2672,  0.2400,  ..., -0.5990, -1.7361, -2.0655],\n",
      "        ...,\n",
      "        [-0.7018, -0.8076, -0.7228,  ...,  1.2536,  1.9405,  1.4483],\n",
      "        [-0.2988,  0.1289, -0.2264,  ...,  0.7696,  1.1767,  0.8359],\n",
      "        [ 0.6532,  0.5471,  0.2121,  ...,  0.5270,  1.9365,  1.5983]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[-1.3594, -0.6967, -0.6070,  ..., -2.1143, -2.3568, -1.6376],\n",
      "        [-0.4078, -0.7423, -0.6401,  ..., -2.4423, -2.2608, -1.3780],\n",
      "        [ 0.2088,  0.3284,  0.1199,  ..., -1.4878, -1.6631, -0.8196],\n",
      "        ...,\n",
      "        [ 0.9200,  1.4280,  0.7775,  ..., -1.6576, -0.6618,  0.0507],\n",
      "        [-0.5813, -0.6482, -0.0750,  ..., -0.9530, -0.4692,  0.1555],\n",
      "        [-1.8227, -1.2731, -1.3243,  ..., -0.8478, -0.9513, -0.7994]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[ 1.2528, -0.3345,  1.0870,  ...,  2.1078, -2.4848, -0.5846],\n",
      "        [-1.0305, -0.2661,  1.2614,  ...,  2.3123, -2.3790, -0.5113],\n",
      "        [-1.7654, -1.2485, -0.0395,  ...,  1.9978, -0.7821, -0.5189],\n",
      "        ...,\n",
      "        [-0.4081, -0.4255, -0.8213,  ...,  2.0731,  1.4121,  0.8488],\n",
      "        [ 0.7652,  2.5208,  0.3814,  ...,  1.8256,  1.3817,  1.5993],\n",
      "        [ 1.5730,  2.5355,  1.8323,  ...,  1.0170,  1.3318,  1.6944]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[-3.5056, -3.0769, -2.4738,  ..., -2.3497, -2.8998, -3.2860],\n",
      "        [-2.8366, -2.7480, -2.0483,  ..., -2.8628, -3.5357, -3.7618],\n",
      "        [-2.2901, -2.2242, -1.7294,  ..., -1.7193, -2.5304, -2.6525],\n",
      "        ...,\n",
      "        [ 0.3257,  0.3810, -0.2146,  ..., -3.7795, -3.2582, -2.8655],\n",
      "        [-0.6202, -0.8929, -0.6697,  ..., -3.9797, -4.1532, -3.3907],\n",
      "        [-1.3944, -0.6851, -0.9818,  ..., -3.4652, -4.0735, -3.1912]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[-1.9662, -1.8460, -1.6205,  ..., -3.2130, -2.8406, -2.9226],\n",
      "        [-1.7410, -1.9420, -1.8886,  ..., -3.3610, -3.0862, -2.9536],\n",
      "        [-1.5818, -1.3125, -1.5205,  ..., -3.0099, -2.5825, -2.5265],\n",
      "        ...,\n",
      "        [ 0.2520,  0.2282,  0.0113,  ..., -0.8594, -0.2166,  0.4106],\n",
      "        [-1.4472, -1.8165, -1.2961,  ..., -0.1567,  0.9438,  0.9520],\n",
      "        [-2.0867, -2.2270, -2.1475,  ...,  0.1639,  1.2220,  0.6603]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[-2.5418, -3.1365, -2.8238,  ..., -2.4494, -2.1784, -2.4542],\n",
      "        [-2.1348, -2.6344, -2.7981,  ..., -2.8777, -1.8744, -2.2573],\n",
      "        [-2.4463, -2.7464, -3.2059,  ..., -1.9929, -1.7061, -1.4957],\n",
      "        ...,\n",
      "        [-1.4996, -2.0123, -0.7511,  ...,  1.1006, -0.1260, -0.7076],\n",
      "        [-2.1769, -2.4725, -1.1517,  ...,  0.9209, -0.2028, -1.1414],\n",
      "        [-2.0224, -1.9618, -1.5833,  ...,  1.6149,  0.6487, -0.3014]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[-0.5677, -0.4793, -0.7874,  ..., -4.1499, -1.0829, -3.9651],\n",
      "        [-0.8396, -1.0058, -1.3825,  ..., -2.8555, -1.1207, -1.5859],\n",
      "        [-1.4875, -1.2909, -1.7063,  ..., -3.5721, -2.2163, -3.9404],\n",
      "        ...,\n",
      "        [-2.8929, -2.6474, -2.1158,  ..., -0.5781, -0.4004, -1.1349],\n",
      "        [-3.5128, -2.7927, -2.9983,  ..., -0.9058,  0.7316, -0.0804],\n",
      "        [-2.1452, -2.8467, -2.3120,  ..., -0.2767, -0.3006,  0.3123]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[ 0.4992,  0.3790,  1.0745,  ..., -0.5822, -1.0787, -1.0737],\n",
      "        [ 0.7387,  0.8558,  1.4133,  ..., -0.8249, -1.1206, -1.4843],\n",
      "        [-0.3670,  0.1635,  0.5666,  ..., -0.9776, -1.0263, -1.2314],\n",
      "        ...,\n",
      "        [ 1.3975,  0.6481,  0.1554,  ...,  0.3049,  0.7412, -0.2594],\n",
      "        [ 2.4004,  2.4367,  0.9592,  ..., -0.2003, -0.7117, -0.4748],\n",
      "        [ 1.9201,  1.9917,  1.1014,  ..., -0.3440,  0.5383, -0.0178]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[-1.1650, -0.7497, -0.7875,  ..., -1.7071, -2.0555, -0.9653],\n",
      "        [-0.0442, -0.4542, -0.7800,  ..., -1.8173, -2.2500, -1.4461],\n",
      "        [ 0.2658,  0.2868, -0.0535,  ..., -1.2255, -1.3220, -0.3388],\n",
      "        ...,\n",
      "        [ 0.9858,  1.6994,  0.8390,  ..., -1.2548, -0.7171,  0.3975],\n",
      "        [ 1.1373,  1.1000,  1.0136,  ..., -1.5451, -1.5509, -0.5188],\n",
      "        [-0.1510,  0.5076,  0.2383,  ..., -1.7818, -2.0851, -1.8516]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[-2.0300, -1.9647, -0.9606,  ..., -1.2760, -1.9827, -2.3401],\n",
      "        [-1.6970, -1.7434, -0.6301,  ..., -0.3247, -2.1726, -1.8497],\n",
      "        [-1.7047, -1.8516, -0.5383,  ..., -0.3992, -1.9026, -1.8058],\n",
      "        ...,\n",
      "        [-0.7058, -0.9869, -0.9424,  ..., -0.6067, -0.7103, -0.7466],\n",
      "        [-0.3507, -0.2732, -0.4103,  ..., -1.4146, -1.5187, -1.1322],\n",
      "        [ 0.4360,  0.4869,  0.3730,  ..., -1.0305, -0.9889, -0.4635]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[ 1.8554,  1.9935,  0.5628,  ...,  2.0531,  2.9402,  4.3731],\n",
      "        [ 1.4120,  0.9138, -0.1802,  ...,  1.0537,  3.0766,  4.0496],\n",
      "        [ 2.9469,  2.1123,  0.8187,  ...,  0.4932,  1.8258,  3.1304],\n",
      "        ...,\n",
      "        [-0.6084, -0.1136,  0.4032,  ...,  1.7341,  2.6088,  2.8917],\n",
      "        [-0.4152, -0.8840,  0.1226,  ...,  2.7256,  3.3711,  2.8579],\n",
      "        [-0.4611, -1.2034, -0.4117,  ...,  2.3035,  3.4113,  2.5520]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[ 1.4306,  1.2208,  0.8608,  ...,  2.2325,  2.0366,  2.1198],\n",
      "        [ 0.9520,  0.8912,  0.6719,  ...,  2.4849,  2.0650,  2.2230],\n",
      "        [ 1.2792,  0.5840,  0.8355,  ...,  1.7094,  1.6742,  2.0695],\n",
      "        ...,\n",
      "        [-1.6463, -1.5650, -1.5031,  ..., -3.2633, -3.6941, -3.6346],\n",
      "        [-0.6078, -0.6858, -0.7479,  ..., -3.1274, -3.8113, -3.1841],\n",
      "        [-0.2785, -0.6036, -0.0621,  ..., -3.1628, -3.4014, -2.6951]],\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "device = 'cpu'\n",
    "# width = 520\n",
    "# img = cv2.imread('image/clint.jpg', cv2.IMREAD_COLOR)\n",
    "# img = cv2.resize(img, (width, width))\n",
    "# img = img.reshape(1, width, width, 3)\n",
    "# img = np.transpose(img, (0, 3, 1, 2))\n",
    "# img = torch.tensor(img).to(device).float() / 255.\n",
    "img = input_batch\n",
    "print(img.shape)\n",
    "# print(resnet(img)['aux'].shape)\n",
    "# pix_pred = resnet(img)['out']\n",
    "print(resnet.classifier)\n",
    "# help(resnet.classifier)\n",
    "# print(resnet.backbone(img)['out'].shape)\n",
    "pred = resnet.classifier(resnet.backbone(img)['out'])\n",
    "print(pred.shape)\n",
    "for i in range(21):\n",
    "    print(pred[0,i,:,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
