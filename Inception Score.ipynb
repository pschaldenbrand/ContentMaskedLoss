{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" https://github.com/sbarratt/inception-score-pytorch/blob/master/inception_score.py \"\"\"\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data\n",
    "\n",
    "from torchvision.models.inception import inception_v3\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "normalize = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inception model\n",
    "inception_model = inception_v3(pretrained=True, transform_input=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_score(imgs, batch_size=32, resize=False, splits=1):\n",
    "    \"\"\"Computes the inception score of the generated images imgs\n",
    "    imgs -- Torch dataset of (3xHxW) numpy images normalized in the range [-1, 1]\n",
    "    batch_size -- batch size for feeding into Inception v3\n",
    "    splits -- number of splits\n",
    "    \"\"\"\n",
    "    N = len(imgs)\n",
    "\n",
    "    assert batch_size > 0\n",
    "    assert N > batch_size\n",
    "\n",
    "    # Set up dataloader\n",
    "    dataloader = torch.utils.data.DataLoader(imgs, batch_size=batch_size)\n",
    "    \n",
    "    inception_model.eval();\n",
    "    up = nn.Upsample(size=(299, 299), mode='bilinear').float().to(device)\n",
    "    def get_pred(x):\n",
    "        if resize:\n",
    "            x = up(x)\n",
    "        x = inception_model(x)\n",
    "        return F.softmax(x).data.cpu().numpy()\n",
    "\n",
    "    # Get predictions\n",
    "    preds = np.zeros((N, 1000))\n",
    "\n",
    "    for i, batch in enumerate(dataloader, 0):\n",
    "        batch = batch.float().to(device)\n",
    "        batchv = Variable(batch)\n",
    "        batch_size_i = batch.size()[0]\n",
    "\n",
    "        preds[i*batch_size:i*batch_size + batch_size_i] = get_pred(batchv)\n",
    "\n",
    "    # Now compute the mean kl-div\n",
    "    split_scores = []\n",
    "\n",
    "    for k in range(splits):\n",
    "        part = preds[k * (N // splits): (k+1) * (N // splits), :]\n",
    "        py = np.mean(part, axis=0)\n",
    "        scores = []\n",
    "        for i in range(part.shape[0]):\n",
    "            pyx = part[i, :]\n",
    "            scores.append(entropy(pyx, py))\n",
    "        split_scores.append(np.exp(np.mean(scores)))\n",
    "\n",
    "    return np.mean(split_scores), np.std(split_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "def load_images_from_path(images_path, width=256):\n",
    "    # loads all images into memory (this might require a lot of RAM!)\n",
    "    image_list = glob.glob(os.path.join(images_path, '*.jpg'))\n",
    "\n",
    "    images = np.zeros((len(image_list), 3, width, width))\n",
    "    i = 0\n",
    "    for img_fn in image_list:\n",
    "        img = cv2.imread(img_fn, cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (width, width), interpolation = cv2.INTER_AREA)\n",
    "        img = img[:,:,::-1] # BGR to RGB\n",
    "        img = img / 255. # 0-1\n",
    "        img = normalize(img) # Normalize\n",
    "        images[i] = img\n",
    "        i += 1\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python36\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final gan 3.0452471956212603 0.08291245330747174\n",
      "final l2 3.0490264758739984 0.14296767185980672\n",
      "final l1 3.452455208449917 0.0924104153592888\n",
      "final cm 3.008645696573719 0.0385964334521512\n",
      "final cml1 3.4733041640342357 0.04700355283420716\n",
      "20 gan 2.067051576149812 0.04347783370869842\n",
      "20 l2 2.2007180896651612 0.022177928665282447\n",
      "20 l1 2.555161535262069 0.04286607222043453\n",
      "20 cm 2.0002639159581816 0.061534563172821424\n",
      "20 cml1 2.161550420584192 0.06397792961397562\n",
      "50 gan 1.9836590849696918 0.021747310565945695\n",
      "50 l2 2.460179597369037 0.07752073113340555\n",
      "50 l1 2.541862396321299 0.13191516826046504\n",
      "50 cm 2.1315592320439363 0.06206673327318728\n",
      "50 cml1 2.394289023377452 0.07174853153242801\n",
      "100 gan 2.2615243486862466 0.05144036416501071\n",
      "100 l2 2.7862814005843193 0.07674621308113994\n",
      "100 l1 2.9307318068103902 0.058639127017219454\n",
      "100 cm 2.6182283436320706 0.07340186508533178\n",
      "100 cml1 2.791565134636432 0.026414792475662658\n",
      "300 gan 2.4848729255434407 0.04484469781809107\n",
      "300 l2 3.1322368882965494 0.06389232672696168\n",
      "300 l1 3.0388210914455955 0.06848342320080034\n",
      "300 cm 2.9226990787777174 0.13467339519700486\n",
      "300 cml1 3.082965199045943 0.07452465315504916\n"
     ]
    }
   ],
   "source": [
    "PARENT_DIR = 'fid'\n",
    "labels = ['GAN', 'L2', 'L1*', 'CM', 'CM + L1*']\n",
    "dir_labels = ['gan', 'l2', 'l1', 'cm', 'cml1']\n",
    "inds_to_save = ['final'] + [20, 50, 100, 300]\n",
    "\n",
    "\n",
    "for painting_ind in inds_to_save:\n",
    "    for dir_label in dir_labels:\n",
    "        gen_image_dir = os.path.join(PARENT_DIR, str(painting_ind), dir_label)\n",
    "        \n",
    "        imgs = load_images_from_path(gen_image_dir, width=299)\n",
    "        \n",
    "#         plt.imshow(np.transpose(imgs[0], (1,2,0)))\n",
    "#         plt.show()\n",
    "                \n",
    "        means, stds = inception_score(imgs, batch_size=8, resize=False, splits=5)\n",
    "        \n",
    "        print(painting_ind, dir_label, means, stds)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
